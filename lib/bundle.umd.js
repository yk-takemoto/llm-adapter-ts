!function(e,t){"object"==typeof exports&&"undefined"!=typeof module?t(exports,require("openai"),require("fs"),require("@anthropic-ai/sdk"),require("@google/generative-ai"),require("groq-sdk")):"function"==typeof define&&define.amd?define(["exports","openai","fs","@anthropic-ai/sdk","@google/generative-ai","groq-sdk"],t):t((e="undefined"!=typeof globalThis?globalThis:e||self)["llm-handler"]={},e.OpenAI,e.fs,e.Anthropic,e.GenerativeAI,e.GroqSDK)}(this,(function(e,t,o,s,n,r){"use strict";class a{constructor(e={apiKey:JSON.parse(process.env.APP_SECRETS||"{}").OPENAI_API_KEY||process.env.OPENAI_API_KEY||"",apiModelChat:process.env.OPENAI_API_MODEL_CHAT,apiModelAudioTranscription:process.env.OPENAI_API_MODEL_AUDIO_TRANSCRIPTION,apiModelText2Speech:process.env.OPENAI_API_MODEL_TEXT2SPEECH},o){this.llmConfig=e,this.initCheck(e),this.openaiClient=o||new t({apiKey:e.apiKey})}initCheck(e){for(const t of Object.keys(this.llmConfig))if(!e[t])throw new Error(`llmConfig.${t} is required but not set.`)}addAdditionalPropertiesElementToObjectType(e,t=!1){if("object"!=typeof e||null===e)return e;if("object"===e.type&&(e.additionalProperties=t,e.properties))for(const o in e.properties)e.properties[o]=this.addAdditionalPropertiesElementToObjectType(e.properties[o],t);return"array"===e.type&&e.items&&(e.items=this.addAdditionalPropertiesElementToObjectType(e.items,t)),e}convertTools(e,t){const o=t?{strict:t}:{};return e.map((e=>({type:"function",function:{name:e.name,description:e.description,...o,parameters:t?this.addAdditionalPropertiesElementToObjectType(e.inputSchema,!t):e.inputSchema}})))}convertResponseFormatJSONSchema(e){return{type:"json_schema",json_schema:{name:e.name,description:e.description,strict:!0,schema:this.addAdditionalPropertiesElementToObjectType(e.inputSchema,!1)}}}async chatCompletions(e,t,o,s){let n=[];if(s){const e=s.toolResults?.map((e=>({tool_call_id:e.id,role:"tool",content:e.content})))||[];n=s.messages.concat(e)}else e.forEach((e=>{n.push({role:"system",content:e})})),n.push({role:"user",content:t.map((e=>e.image?{type:"image_url",image_url:{url:e.image.url,detail:e.image.detail||"auto"}}:e.audio?{type:"input_audio",input_audio:{data:e.audio.data,format:e.audio.format||"mp3"}}:{type:"text",text:e.text||""}))});let r={},a={};o.tools&&o.tools.length>0&&(r="function"===o.purposeOfTools?{tools:this.convertTools(o.tools,!0),tool_choice:o.toolChoice||"auto"}:{},a="response_format"===o.purposeOfTools?{response_format:this.convertResponseFormatJSONSchema(o.tools[0])}:{});const i={model:this.llmConfig.apiModelChat,messages:n,max_tokens:o.maxTokens||1028,temperature:o.temperature??.7,...r,...a};let c={text:"",tools:[],messages:[]};try{console.log("[chatCompletions] start -- updatedMessages: ",JSON.stringify(n));const e=(await this.openaiClient.chat.completions.create(i)).choices[0],t=e.finish_reason;console.log(`[chatCompletions] end -- choices[0].message: ${JSON.stringify(e.message)} finishReason: ${t}`);let o=[];e.message&&(n.push(e.message),o="tool_calls"===t&&e.message.tool_calls?.map((e=>({id:e.id,name:e.function.name,arguments:JSON.parse(e.function.arguments)})))||[]),c={text:e.message?.content,tools:o,messages:n}}catch(e){throw console.log("[chatCompletions] Error: ",e),e}return console.log("[chatCompletions] response: ",c),c}async speechToText(e,t){const s={file:o.createReadStream(e),model:this.llmConfig.apiModelAudioTranscription,language:t?.language||"ja"};try{return(await this.openaiClient.audio.transcriptions.create(s)).text}catch(e){throw console.log("[speechToText] Error: ",e),e}}async textToSpeech(e,t){const o={model:this.llmConfig.apiModelText2Speech||"tts-1",input:e,voice:t?.voice||"alloy",response_format:t?.responseFormat||"mp3"};try{const e=await this.openaiClient.audio.speech.create(o),t=e.headers.get("content-type"),s=await e.arrayBuffer();return{contentType:t,content:Buffer.from(s)}}catch(e){throw console.log("[textToSpeech] Error: ",e),e}}}const i={OpenAI:a,AzureOpenAI:class extends a{constructor(e={apiKey:JSON.parse(process.env.APP_SECRETS||"{}").AZURE_OPENAI_API_KEY||process.env.AZURE_OPENAI_API_KEY||"",apiModelChat:process.env.AZURE_OPENAI_API_DEPLOYMENT_CHAT,apiModelAudioTranscription:process.env.AZURE_OPENAI_API_DEPLOYMENT_AUDIO_TRANSCRIPTION,apiModelText2Speech:process.env.AZURE_OPENAI_API_DEPLOYMENT_TEXT2SPEECH,endpoint:process.env.AZURE_OPENAI_ENDPOINT,apiVersion:process.env.OPENAI_API_VERSION}){super(e,new t.AzureOpenAI({apiKey:e.apiKey,endpoint:e.endpoint,apiVersion:e.apiVersion}))}},Anthropic:class{constructor(e={apiKey:JSON.parse(process.env.APP_SECRETS||"{}").ANTHROPIC_API_KEY||process.env.ANTHROPIC_API_KEY||"",apiModelChat:process.env.ANTHROPIC_API_MODEL_CHAT}){this.llmConfig=e,this.initCheck(e),this.anthropicClient=new s({apiKey:e.apiKey})}initCheck(e){for(const t of Object.keys(this.llmConfig))if(!e[t])throw new Error(`llmConfig.${t} is required but not set.`)}convertTools(e){return e.map((e=>({name:e.name,description:e.description,input_schema:e.inputSchema})))}async convertImageUrlToBase64(e){try{const t=await fetch(e),o=await t.arrayBuffer(),s=Buffer.from(o),n=t.headers.get("content-type")||"image/jpeg";return{mimeType:n,base64Content:s.toString("base64")}}catch(e){throw new Error(`Failed to fetch or convert image: ${e}`)}}convertMessagesForHistory(e){return e.map((e=>({role:e.role,content:Array.isArray(e.content)?e.content.map((e=>"image"===e.type?{...e,source:{...e.source,data:"ommitted"}}:e)):e.content})))}async chatCompletions(e,t,o,s){const n=[];e.forEach((e=>{n.push({type:"text",text:e})}));let r=[];if(s){const e=s.toolResults?.map((e=>({tool_use_id:e.id,type:"tool_result",content:e.content})))||[];r=s.messages.concat({role:"user",content:e})}else{const e=await Promise.all(t.map((async e=>{if(e.image){const{mimeType:t,base64Content:o}=await this.convertImageUrlToBase64(e.image.url);return{type:"image",source:{type:"base64",media_type:t,data:o}}}return{type:"text",text:e.text||""}})));r.push({role:"user",content:e})}const a=o.tools&&o.tools.length>0?{tools:this.convertTools(o.tools),tool_choice:{type:o.toolChoice||"auto"}}:{},i={model:this.llmConfig.apiModelChat,messages:r,system:n,max_tokens:o.maxTokens||1028,temperature:o.temperature??.7,...a};let c={text:"",tools:[],messages:[]};try{const e=this.convertMessagesForHistory(r);console.log("[chatCompletions] start -- covertedSystemPrompt: ",JSON.stringify(n)," -- historyMessages: ",JSON.stringify(e));const t=await this.anthropicClient.messages.create(i),s=t.content,a=t.stop_reason;console.log(`[chatCompletions] end -- contents: ${JSON.stringify(s)} stopReason: ${a}`);let l=[];t&&(e.push({role:t.role,content:s}),l="tool_use"===a&&s?.filter((e=>"tool_use"===e.type)).map((e=>({id:e.id,name:e.name,arguments:JSON.parse(JSON.stringify(e.input))})))||[]),c={text:l.length>0&&"response_format"===o.purposeOfTools?JSON.stringify(l[0].arguments):s[0].text||null,tools:l,messages:e}}catch(e){throw console.log("[chatCompletions] Error: ",e),e}return console.log("[chatCompletions] response: ",c),c}async speechToText(e,t){try{return"unsupported"}catch(e){throw console.log("[speechToText] Error: ",e),e}}async textToSpeech(e,t){try{const e="wav"===t?.responseFormat||"aac"===t?.responseFormat?t.responseFormat:"mp3",s=await o.promises.readFile(`audio/sorry.ja.${e}`);return{contentType:"mp3"===e?"audio/mpeg":`audio/${e}`,content:s}}catch(e){throw console.log("[textToSpeech] Error: ",e),e}}},Google:class{constructor(e={apiKey:JSON.parse(process.env.APP_SECRETS||"{}").GEMINI_API_KEY||process.env.GEMINI_API_KEY||"",apiModelChat:process.env.GEMINI_API_MODEL_CHAT}){this.llmConfig=e,this.initCheck(e),this.geminiClient=new n.GoogleGenerativeAI(e.apiKey)}initCheck(e){for(const t of Object.keys(this.llmConfig))if(!e[t])throw new Error(`llmConfig.${t} is required but not set.`)}convertTools(e){return[{functionDeclarations:e.map((e=>({name:e.name,description:e.description,parameters:e.inputSchema})))}]}convertResponseFormatJSONSchema(e){return{responseMimeType:"application/json",responseSchema:e.inputSchema}}async convertImageUrlToBase64(e){try{const t=await fetch(e),o=await t.arrayBuffer(),s=Buffer.from(o),n=t.headers.get("content-type")||"image/jpeg";return{mimeType:n,base64Content:s.toString("base64")}}catch(e){throw new Error(`Failed to fetch or convert image: ${e}`)}}convertMessagesForHistory(e){return e.map((e=>({role:e.role,parts:e.parts.map((e=>e.inlineData?.data?{...e,inlineData:{...e.inlineData,data:"ommitted"}}:e))})))}async chatCompletions(e,t,o,s){const r={role:"model",parts:[]};e.forEach((e=>{r.parts.push({text:e})}));let a=[];if(s){const e=s.toolResults?.map((e=>({text:e.content})))||[];a=s.messages.concat({role:"user",parts:e})}else{const e=await Promise.all(t.map((async e=>{if(e.image){const{mimeType:t,base64Content:o}=await this.convertImageUrlToBase64(e.image.url);return{inlineData:{mimeType:t,data:o}}}return{text:e.text||""}})));a.push({role:"user",parts:e})}let i={},c={};o.tools&&o.tools.length>0&&(i="function"===o.purposeOfTools?{tools:this.convertTools(o.tools),toolConfig:{functionCallingConfig:{mode:String(o.toolChoice).toUpperCase()||n.FunctionCallingMode.AUTO}}}:{},c="response_format"===o.purposeOfTools?this.convertResponseFormatJSONSchema(o.tools[0]):{});const l={safetySettings:[{category:n.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,threshold:n.HarmBlockThreshold.BLOCK_ONLY_HIGH}],generationConfig:{maxOutputTokens:o.maxTokens||1028,temperature:o.temperature??.7,...c},model:this.llmConfig.apiModelChat,systemInstruction:r,...i};let p={text:"",tools:[],messages:[]};try{const e=this.convertMessagesForHistory(a);console.log("[chatCompletions] start -- historyMessages: ",JSON.stringify(e));const t=(await this.geminiClient.getGenerativeModel(l).generateContent({contents:a})).response,o=t.text(),s=t.functionCalls(),n=t.candidates&&t.candidates[0].finishReason;console.log(`[chatCompletions] end -- response.text: ${o} response.functionCalls: ${JSON.stringify(s)} finishReason: ${n}`);let r=[];if(t){const t=[];r=s&&s?.map((e=>(t.push({functionCall:e}),{id:"",name:e.name,arguments:JSON.parse(JSON.stringify(e.args))})))||[],e.push({role:"model",parts:t})}p={text:o,tools:r,messages:e}}catch(e){throw console.log("[chatCompletions] Error: ",e),e}return console.log("[chatCompletions] response: ",p),p}async speechToText(e,t){try{return"unsupported"}catch(e){throw console.log("[speechToText] Error: ",e),e}}async textToSpeech(e,t){try{const e="wav"===t?.responseFormat||"aac"===t?.responseFormat?t.responseFormat:"mp3",s=await o.promises.readFile(`audio/sorry.ja.${e}`);return{contentType:"mp3"===e?"audio/mpeg":`audio/${e}`,content:s}}catch(e){throw console.log("[textToSpeech] Error: ",e),e}}},Groq:class{constructor(e={apiKey:JSON.parse(process.env.APP_SECRETS||"{}").GROQ_API_KEY||process.env.GROQ_API_KEY||"",apiModelChat:process.env.GROQ_API_MODEL_CHAT}){this.llmConfig=e,this.initCheck(e),this.groqClient=new r.Groq({apiKey:e.apiKey})}initCheck(e){for(const t of Object.keys(this.llmConfig))if(!e[t])throw new Error(`llmConfig.${t} is required but not set.`)}convertTools(e){return e.map((e=>({type:"function",function:{name:e.name,description:e.description,parameters:e.inputSchema}})))}async chatCompletions(e,t,o,s){let n=[];if(s){const e=s.toolResults?.map((e=>({tool_call_id:e.id,role:"tool",content:e.content})))||[];n=s.messages.concat(e)}else{t.some((e=>e.image))?n.push({role:"user",content:e.map((e=>({type:"text",text:e})))}):e.forEach((e=>{n.push({role:"system",content:e})})),n.push({role:"user",content:t.map((e=>e.image?{type:"image_url",image_url:{url:e.image.url,detail:e.image.detail||"auto"}}:{type:"text",text:e.text||""}))})}let r={},a={};o.tools&&o.tools.length>0&&(r="function"===o.purposeOfTools?{tools:this.convertTools(o.tools),tool_choice:o.toolChoice||"auto"}:{},a="response_format"===o.purposeOfTools?{response_format:{type:"json_object"}}:{});const i={model:this.llmConfig.apiModelChat,messages:n,max_tokens:o.maxTokens||1028,temperature:o.temperature??.7,...r,...a};let c={text:"",tools:[],messages:[]};try{console.log("[chatCompletions] start -- updatedMessages: ",JSON.stringify(n));const e=(await this.groqClient.chat.completions.create(i)).choices[0],t=e.finish_reason;console.log(`[chatCompletions] end -- choices[0].message: ${JSON.stringify(e.message)} finishReason: ${t}`);let o=[];e.message&&(n.push(e.message),o="tool_calls"===t&&e.message.tool_calls?.map((e=>({id:e.id,name:e.function.name,arguments:JSON.parse(e.function.arguments)})))||[]),c={text:e.message?.content,tools:o,messages:n}}catch(e){throw console.log("[chatCompletions] Error: ",e),e}return console.log("[chatCompletions] response: ",c),c}async speechToText(e,t){try{return"unsupported"}catch(e){throw console.log("[speechToText] Error: ",e),e}}async textToSpeech(e,t){try{const e="wav"===t?.responseFormat||"aac"===t?.responseFormat?t.responseFormat:"mp3",s=await o.promises.readFile(`audio/sorry.ja.${e}`);return{contentType:"mp3"===e?"audio/mpeg":`audio/${e}`,content:s}}catch(e){throw console.log("[textToSpeech] Error: ",e),e}}}};e.llmAdapterBuilder=e=>new(0,i[e])}));
//# sourceMappingURL=bundle.umd.js.map
