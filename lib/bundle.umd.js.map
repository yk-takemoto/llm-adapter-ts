{"version":3,"file":"bundle.umd.js","sources":["../src/openai_adapter.ts","../src/llm_adapter_builder.ts","../src/azure_openai_adapter.ts","../src/anthropic_adapter.ts","../src/gemini_adapter.ts","../src/groq_adapter.ts","../src/llm_adapter_schemas.ts"],"sourcesContent":["import OpenAI from \"openai\";\nimport { createReadStream } from \"fs\";\nimport { z } from \"zod\";\nimport { LlmAdapter } from \"@/llm_adapter\";\nimport { LlmChatCompletionsContent, LlmChatCompletionsOptions, LlmChatCompletionsResponse, LlmTextToSpeechResponse, McpTool } from \"@/llm_adapter_schemas\";\n\nexport class OpenAIAdapter<T extends OpenAI> implements LlmAdapter {\n  protected llmConfig;\n  protected openaiClient;\n\n  constructor(\n    llmConfig = {\n      apiKey: JSON.parse(process.env.APP_SECRETS || \"{}\").OPENAI_API_KEY || process.env.OPENAI_API_KEY,\n      apiModelChat: process.env.OPENAI_API_MODEL_CHAT,\n      apiModelAudioTranscription: process.env.OPENAI_API_MODEL_AUDIO_TRANSCRIPTION,\n      apiModelText2Speech: process.env.OPENAI_API_MODEL_TEXT2SPEECH,\n    },\n    llmConfigSchema = z.object({\n      apiKey: z.string().min(1, \"OPENAI_API_KEY is required\"),\n      apiModelChat: z.string().min(1, \"OPENAI_API_MODEL_CHAT is required\"),\n      apiModelAudioTranscription: z.string().optional(),\n      apiModelText2Speech: z.string().optional(),\n    }),\n    apiClient?: T,\n  ) {\n    this.llmConfig = llmConfigSchema.parse(llmConfig);\n    this.openaiClient = apiClient || new OpenAI({ apiKey: llmConfig.apiKey });\n  }\n\n  private addAdditionalPropertiesElementToObjectType(schema: any, bool: boolean = false) {\n    if (typeof schema !== \"object\" || schema === null) {\n      return schema;\n    }\n    if (schema.type === \"object\") {\n      schema.additionalProperties = bool;\n      if (schema.properties) {\n        for (const key in schema.properties) {\n          schema.properties[key] = this.addAdditionalPropertiesElementToObjectType(schema.properties[key], bool);\n        }\n      }\n    }\n    if (schema.type === \"array\" && schema.items) {\n      schema.items = this.addAdditionalPropertiesElementToObjectType(schema.items, bool);\n    }\n    return schema;\n  }\n\n  private convertTools(tools: McpTool[], isStrict?: boolean): OpenAI.ChatCompletionTool[] {\n    const strict = isStrict\n      ? {\n          strict: isStrict,\n        }\n      : {};\n    return tools.map((tool) => {\n      return {\n        type: \"function\",\n        function: {\n          name: tool.name,\n          description: tool.description,\n          ...strict,\n          parameters: isStrict ? this.addAdditionalPropertiesElementToObjectType(tool.inputSchema, !isStrict) : tool.inputSchema,\n        },\n      };\n    });\n  }\n\n  private convertResponseFormatJSONSchema(tool: McpTool): OpenAI.ResponseFormatJSONSchema {\n    return {\n      type: \"json_schema\",\n      json_schema: {\n        name: tool.name,\n        description: tool.description,\n        strict: true,\n        schema: this.addAdditionalPropertiesElementToObjectType(tool.inputSchema, false),\n      },\n    };\n  }\n\n  async chatCompletions(\n    systemPrompt: string[],\n    newMessageContents: LlmChatCompletionsContent[],\n    options: LlmChatCompletionsOptions,\n    inProgress?: {\n      messages: OpenAI.ChatCompletionMessageParam[];\n      toolResults?: {\n        id: string;\n        content: string;\n      }[];\n    },\n  ): Promise<LlmChatCompletionsResponse> {\n    let updatedMessages: OpenAI.ChatCompletionMessageParam[] = [];\n    if (inProgress) {\n      const resMessages =\n        inProgress.toolResults?.map((toolResult) => {\n          return {\n            tool_call_id: toolResult.id,\n            role: \"tool\",\n            content: toolResult.content,\n          } as OpenAI.ChatCompletionMessageParam;\n        }) || [];\n      updatedMessages = inProgress.messages.concat(resMessages);\n    } else {\n      systemPrompt.forEach((msg) => {\n        updatedMessages.push({\n          role: \"system\",\n          content: msg,\n        });\n      });\n    }\n    if (newMessageContents.length > 0) {\n      updatedMessages.push({\n        role: \"user\",\n        content: newMessageContents.map((content) => {\n          return content.image\n            ? {\n                type: \"image_url\",\n                image_url: {\n                  url: content.image.url,\n                  detail: content.image.detail || \"auto\",\n                },\n              }\n            : content.audio\n              ? {\n                  type: \"input_audio\",\n                  input_audio: {\n                    data: content.audio.data,\n                    format: content.audio.format || \"mp3\",\n                  },\n                }\n              : {\n                  type: \"text\",\n                  text: content.text || \"\",\n                };\n        }),\n      });\n    }\n\n    let toolsOption = {};\n    let resFormatOption = {};\n    if (options.tools && options.tools.length > 0) {\n      toolsOption =\n        options.toolOption.type === \"function\" || options.toolOption.type === \"function_strict\"\n          ? {\n              tools: this.convertTools(options.tools, options.toolOption.type === \"function_strict\"),\n              tool_choice: options.toolOption.choice || (\"auto\" as OpenAI.ChatCompletionToolChoiceOption),\n            }\n          : {};\n      resFormatOption =\n        options.toolOption.type === \"response_format\"\n          ? {\n              response_format: this.convertResponseFormatJSONSchema(options.tools[0]),\n            }\n          : {};\n    }\n\n    const chatOtions = {\n      model: this.llmConfig.apiModelChat,\n      messages: updatedMessages,\n      max_tokens: (options.toolOption.maxTokens as number) || 1028,\n      temperature: (options.toolOption.temperature as number) ?? 0.7,\n      ...toolsOption,\n      ...resFormatOption,\n    };\n    let response: LlmChatCompletionsResponse = {\n      text: \"\",\n      tools: [],\n      messages: [],\n    };\n    try {\n      // debug\n      console.log(\"[chatCompletions] start -- updatedMessages: \", JSON.stringify(updatedMessages));\n      const chatResponse = await this.openaiClient.chat.completions.create(chatOtions);\n      const choice = chatResponse.choices[0];\n      const finishReason = choice.finish_reason;\n      // debug\n      console.log(`[chatCompletions] end -- choices[0].message: ${JSON.stringify(choice.message)} finishReason: ${finishReason}`);\n\n      let resTools: { id: string; name: string; arguments: Record<string, any> }[] = [];\n      if (choice.message) {\n        updatedMessages.push(choice.message);\n        resTools =\n          finishReason === \"tool_calls\"\n            ? choice.message.tool_calls?.map((tool_call) => {\n                return {\n                  id: tool_call.id,\n                  name: tool_call.function.name,\n                  arguments: JSON.parse(tool_call.function.arguments) as Record<string, any>,\n                };\n              }) || []\n            : [];\n      }\n\n      response = {\n        text: choice.message?.content,\n        tools: resTools,\n        messages: updatedMessages,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[chatCompletions] Error: \", error);\n      throw error;\n    }\n\n    // debug\n    console.log(\"[chatCompletions] response: \", response);\n    return response;\n  }\n\n  async speechToText(audioFilePath: string, options?: Record<string, any>): Promise<string> {\n    const speechOtions = {\n      file: createReadStream(audioFilePath),\n      model: this.llmConfig.apiModelAudioTranscription || \"whisper-1\",\n      language: options?.language || \"ja\",\n    };\n    try {\n      const response = await this.openaiClient.audio.transcriptions.create(speechOtions);\n      return response.text;\n    } catch (error) {\n      // debug\n      console.log(\"[speechToText] Error: \", error);\n      throw error;\n    }\n  }\n\n  async textToSpeech(message: string, options?: Record<string, any>): Promise<LlmTextToSpeechResponse> {\n    const speechOtions = {\n      model: this.llmConfig.apiModelText2Speech || \"tts-1\",\n      input: message,\n      voice: options?.voice || \"alloy\",\n      response_format: options?.responseFormat || \"mp3\",\n    };\n    try {\n      const response = await this.openaiClient.audio.speech.create(speechOtions);\n      const contentType = response.headers.get(\"content-type\");\n      const arrayBuffer = await response.arrayBuffer();\n      return {\n        contentType: contentType!,\n        content: Buffer.from(arrayBuffer),\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[textToSpeech] Error: \", error);\n      throw error;\n    }\n  }\n}\n","import { LlmAdapter } from \"@/llm_adapter\";\nimport { OpenAIAdapter } from \"@/openai_adapter\";\nimport { AzureOpenAIAdapter } from \"@/azure_openai_adapter\";\nimport { AnthropicAdapter } from \"@/anthropic_adapter\";\nimport { GeminiAdapter } from \"@/gemini_adapter\";\nimport { GroqAdapter } from \"@/groq_adapter\";\n\ntype LlmAdapterConstructor = new (...args: any[]) => LlmAdapter;\nconst llmAdapterClasses: Record<string, LlmAdapterConstructor> = {\n  OpenAI: OpenAIAdapter,\n  AzureOpenAI: AzureOpenAIAdapter,\n  Anthropic: AnthropicAdapter,\n  Google: GeminiAdapter,\n  Groq: GroqAdapter,\n};\n\nconst llmAdapterBuilder = (llmId: string): LlmAdapter => {\n  const llmAdapterClass = llmAdapterClasses[llmId];\n  return new llmAdapterClass();\n};\n\nexport default llmAdapterBuilder;\n","import { AzureOpenAI } from \"openai\";\nimport { z } from \"zod\";\nimport { OpenAIAdapter } from \"@/openai_adapter\";\n\nexport class AzureOpenAIAdapter extends OpenAIAdapter<AzureOpenAI> {\n  constructor(\n    llmConfig = {\n      apiKey: JSON.parse(process.env.APP_SECRETS || \"{}\").AZURE_OPENAI_API_KEY || process.env.AZURE_OPENAI_API_KEY,\n      apiModelChat: process.env.AZURE_OPENAI_API_DEPLOYMENT_CHAT,\n      apiModelAudioTranscription: process.env.AZURE_OPENAI_API_DEPLOYMENT_AUDIO_TRANSCRIPTION,\n      apiModelText2Speech: process.env.AZURE_OPENAI_API_DEPLOYMENT_TEXT2SPEECH,\n      endpoint: process.env.AZURE_OPENAI_ENDPOINT,\n      apiVersion: process.env.OPENAI_API_VERSION,\n    },\n    llmConfigSchema = z.object({\n      apiKey: z.string().min(1, \"AZURE_OPENAI_API_KEY is required\"),\n      apiModelChat: z.string().min(1, \"AZURE_OPENAI_API_DEPLOYMENT_CHAT is required\"),\n      apiModelAudioTranscription: z.string().optional(),\n      apiModelText2Speech: z.string().optional(),\n      endpoint: z.string().min(1, \"AZURE_OPENAI_ENDPOINT is required\"),\n      apiVersion: z.string().min(1, \"OPENAI_API_VERSION is required\"),\n    }),\n  ) {\n    const apiClient = new AzureOpenAI({ apiKey: llmConfig.apiKey, endpoint: llmConfig.endpoint, apiVersion: llmConfig.apiVersion });\n    super(llmConfig, llmConfigSchema, apiClient);\n  }\n}\n","import { promises as fs } from \"fs\";\nimport { z } from \"zod\";\nimport Anthropic from \"@anthropic-ai/sdk\";\nimport { LlmAdapter } from \"@/llm_adapter\";\nimport { LlmChatCompletionsContent, LlmChatCompletionsOptions, LlmChatCompletionsResponse, LlmTextToSpeechResponse, McpTool } from \"@/llm_adapter_schemas\";\n\nexport class AnthropicAdapter implements LlmAdapter {\n  protected llmConfig;\n  protected anthropicClient;\n\n  constructor(\n    llmConfig = {\n      apiKey: JSON.parse(process.env.APP_SECRETS || \"{}\").ANTHROPIC_API_KEY || process.env.ANTHROPIC_API_KEY,\n      apiModelChat: process.env.ANTHROPIC_API_MODEL_CHAT,\n    },\n    llmConfigSchema = z.object({\n      apiKey: z.string().min(1, \"ANTHROPIC_API_KEY is required\"),\n      apiModelChat: z.string().min(1, \"ANTHROPIC_API_MODEL_CHAT is required\"),\n    }),\n  ) {\n    this.llmConfig = llmConfigSchema.parse(llmConfig);\n    this.anthropicClient = new Anthropic({ apiKey: llmConfig.apiKey });\n  }\n\n  private convertTools(tools: McpTool[]): Anthropic.Tool[] {\n    return tools.map((tool) => {\n      return {\n        name: tool.name,\n        description: tool.description,\n        input_schema: tool.inputSchema as Anthropic.Tool.InputSchema,\n      };\n    });\n  }\n\n  private async convertImageUrlToBase64(imageUrl: string): Promise<{\n    mimeType: string;\n    base64Content: string;\n  }> {\n    try {\n      const response = await fetch(imageUrl);\n      const arrayBuffer = await response.arrayBuffer();\n      const buffer = Buffer.from(arrayBuffer);\n\n      const mimeType = response.headers.get(\"content-type\") || \"image/jpeg\";\n      const base64Content = buffer.toString(\"base64\");\n      return { mimeType, base64Content };\n    } catch (error) {\n      throw new Error(`Failed to fetch or convert image: ${error}`);\n    }\n  }\n\n  private convertMessagesForHistory(messages: Anthropic.MessageParam[]): Anthropic.MessageParam[] {\n    return messages.map((message) => ({\n      role: message.role,\n      content: Array.isArray(message.content)\n        ? message.content.map((item) =>\n            item.type === \"image\" ? ({ ...item, source: { ...item.source, data: \"ommitted\" } } as Anthropic.ImageBlockParam) : item,\n          )\n        : message.content,\n    }));\n  }\n\n  async chatCompletions(\n    systemPrompt: string[],\n    newMessageContents: LlmChatCompletionsContent[],\n    options: LlmChatCompletionsOptions,\n    inProgress?: {\n      messages: Anthropic.MessageParam[];\n      toolResults?: {\n        id: string;\n        content: string;\n      }[];\n    },\n  ): Promise<LlmChatCompletionsResponse> {\n    const covertedSystemPrompt: Anthropic.TextBlockParam[] = [];\n    systemPrompt.forEach((msg) => {\n      covertedSystemPrompt.push({\n        type: \"text\",\n        text: msg,\n      });\n    });\n    let updatedMessages: Anthropic.MessageParam[] = [];\n    if (inProgress) {\n      const resMessages =\n        inProgress.toolResults?.map((toolResult) => {\n          return {\n            tool_use_id: toolResult.id,\n            type: \"tool_result\" as const,\n            content: toolResult.content,\n          } as Anthropic.ToolResultBlockParam;\n        }) || [];\n      updatedMessages = inProgress.messages.concat({ role: \"user\", content: resMessages });\n    }\n    if (newMessageContents.length > 0) {\n      const list = await Promise.all(\n        newMessageContents.map(async (content) => {\n          if (content.image) {\n            const { mimeType, base64Content } = await this.convertImageUrlToBase64(content.image.url);\n            return {\n              type: \"image\",\n              source: {\n                type: \"base64\",\n                media_type: mimeType,\n                data: base64Content,\n              },\n            } as Anthropic.ImageBlockParam;\n          } else {\n            return {\n              type: \"text\",\n              text: content.text || \"\",\n            } as Anthropic.TextBlockParam;\n          }\n        }),\n      );\n      updatedMessages.push({\n        role: \"user\",\n        content: list,\n      });\n    }\n\n    const toolsOption =\n      options.tools && options.tools.length > 0\n        ? {\n            tools: this.convertTools(options.tools),\n            tool_choice: { type: options.toolOption.choice || \"auto\" } as Anthropic.ToolChoice,\n          }\n        : {};\n\n    const chatOtions: Anthropic.MessageCreateParams = {\n      model: this.llmConfig.apiModelChat,\n      messages: updatedMessages,\n      system: covertedSystemPrompt,\n      max_tokens: (options.toolOption.maxTokens as number) || 1028,\n      temperature: (options.toolOption.temperature as number) ?? 0.7,\n      ...toolsOption,\n    };\n    let response: LlmChatCompletionsResponse = {\n      text: \"\",\n      tools: [],\n      messages: [],\n    };\n    try {\n      // For history\n      const historyMessages = this.convertMessagesForHistory(updatedMessages);\n\n      // debug\n      console.log(\n        \"[chatCompletions] start -- covertedSystemPrompt: \",\n        JSON.stringify(covertedSystemPrompt),\n        \" -- historyMessages: \",\n        JSON.stringify(historyMessages),\n      );\n      const chatResponse = await this.anthropicClient.messages.create(chatOtions);\n      const contents = chatResponse.content;\n      const stopReason = chatResponse.stop_reason;\n      // debug\n      console.log(`[chatCompletions] end -- contents: ${JSON.stringify(contents)} stopReason: ${stopReason}`);\n\n      let resTools: { id: string; name: string; arguments: Record<string, any> }[] = [];\n      if (chatResponse) {\n        historyMessages.push({\n          role: chatResponse.role,\n          content: contents,\n        });\n        resTools =\n          stopReason === \"tool_use\"\n            ? contents\n                ?.filter((contentBlock) => contentBlock.type === \"tool_use\")\n                .map((contentBlock) => {\n                  return {\n                    id: contentBlock.id,\n                    name: contentBlock.name,\n                    arguments: JSON.parse(JSON.stringify(contentBlock.input)) as Record<string, any>,\n                  };\n                }) || []\n            : [];\n      }\n\n      response = {\n        text:\n          resTools.length > 0 && options.toolOption.type === \"response_format\"\n            ? JSON.stringify(resTools[0].arguments)\n            : (contents[0] as Anthropic.TextBlock).text || null,\n        tools: resTools,\n        messages: historyMessages,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[chatCompletions] Error: \", error);\n      throw error;\n    }\n\n    // debug\n    console.log(\"[chatCompletions] response: \", response);\n    return response;\n  }\n\n  async speechToText(__: string, ___?: Record<string, any>): Promise<string> {\n    //================ Not supported\n    try {\n      return \"unsupported\";\n    } catch (error) {\n      // debug\n      console.log(\"[speechToText] Error: \", error);\n      throw error;\n    }\n  }\n\n  async textToSpeech(_: string, options?: Record<string, any>): Promise<LlmTextToSpeechResponse> {\n    //================ Not supported\n    try {\n      const sorryFormat = options?.responseFormat === \"wav\" || options?.responseFormat === \"aac\" ? options.responseFormat : \"mp3\";\n      const sorry = await fs.readFile(`audio/sorry.ja.${sorryFormat}`);\n      const contentType = sorryFormat === \"mp3\" ? \"audio/mpeg\" : `audio/${sorryFormat}`;\n      return {\n        contentType: contentType,\n        content: sorry,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[textToSpeech] Error: \", error);\n      throw error;\n    }\n  }\n}\n","import { promises as fs } from \"fs\";\nimport { z } from \"zod\";\nimport {\n  GoogleGenerativeAI,\n  HarmBlockThreshold,\n  HarmCategory,\n  ModelParams,\n  Content,\n  FunctionDeclaration,\n  Tool,\n  FunctionCallingMode,\n  FunctionCallPart,\n  GenerationConfig,\n  ResponseSchema,\n  Part,\n} from \"@google/generative-ai\";\nimport { LlmAdapter } from \"@/llm_adapter\";\nimport { LlmChatCompletionsContent, LlmChatCompletionsOptions, LlmChatCompletionsResponse, LlmTextToSpeechResponse, McpTool } from \"@/llm_adapter_schemas\";\n\nexport class GeminiAdapter implements LlmAdapter {\n  protected llmConfig;\n  protected geminiClient;\n\n  constructor(\n    llmConfig = {\n      apiKey: JSON.parse(process.env.APP_SECRETS || \"{}\").GEMINI_API_KEY || process.env.GEMINI_API_KEY,\n      apiModelChat: process.env.GEMINI_API_MODEL_CHAT,\n    },\n    llmConfigSchema = z.object({\n      apiKey: z.string().min(1, \"GEMINI_API_KEY is required\"),\n      apiModelChat: z.string().min(1, \"GEMINI_API_MODEL_CHAT is required\"),\n    }),\n  ) {\n    this.llmConfig = llmConfigSchema.parse(llmConfig);\n    this.geminiClient = new GoogleGenerativeAI(llmConfig.apiKey);\n  }\n\n  // A function to delete parameters such as additionalProperties because the GeminiAPI tool schema does not support jsonSchema7.\n  private cleanJsonSchema(schema: Record<string, any>): Record<string, any> {\n    if (typeof schema !== \"object\" || schema === null) {\n      return schema;\n    }\n    if (schema.type === \"object\") {\n      const cleanedSchema: Record<string, any> = {};\n      Object.keys(schema).forEach((key) => {\n        if (key !== \"additionalProperties\" && key !== \"$schema\") {\n          if (key === \"properties\") {\n            cleanedSchema.properties = Object.keys(schema.properties).reduce(\n              (acc, propKey) => ({\n                ...acc,\n                [propKey]: this.cleanJsonSchema(schema.properties[propKey]),\n              }),\n              {},\n            );\n          } else {\n            cleanedSchema[key] = schema[key];\n          }\n        }\n      });\n      return cleanedSchema;\n    }\n    if (schema.type === \"array\" && schema.items) {\n      const { items, ...rest } = schema;\n      return {\n        ...rest,\n        items: this.cleanJsonSchema(items),\n      };\n    }\n    return schema;\n  }\n\n  private convertTools(tools: McpTool[]): Tool[] {\n    const functions = tools.map((tool) => {\n      return {\n        name: tool.name,\n        description: tool.description,\n        parameters: this.cleanJsonSchema(tool.inputSchema),\n      } as FunctionDeclaration;\n    });\n    // debug\n    console.log(\"[convertTools] functions: \", JSON.stringify(functions, null, 2));\n    return [{ functionDeclarations: functions }];\n  }\n\n  private convertResponseFormatJSONSchema(tool: McpTool): GenerationConfig {\n    return {\n      responseMimeType: \"application/json\",\n      responseSchema: this.cleanJsonSchema(tool.inputSchema) as ResponseSchema,\n    };\n  }\n\n  private async convertImageUrlToBase64(imageUrl: string): Promise<{\n    mimeType: string;\n    base64Content: string;\n  }> {\n    try {\n      const response = await fetch(imageUrl);\n      const arrayBuffer = await response.arrayBuffer();\n      const buffer = Buffer.from(arrayBuffer);\n\n      const mimeType = response.headers.get(\"content-type\") || \"image/jpeg\";\n      const base64Content = buffer.toString(\"base64\");\n      return { mimeType, base64Content };\n    } catch (error) {\n      throw new Error(`Failed to fetch or convert image: ${error}`);\n    }\n  }\n\n  private convertMessagesForHistory(messages: Content[]): Content[] {\n    return messages.map((message) => ({\n      role: message.role,\n      parts: message.parts.map((part) => (part.inlineData?.data ? ({ ...part, inlineData: { ...part.inlineData, data: \"ommitted\" } } as Part) : part)),\n    }));\n  }\n\n  async chatCompletions(\n    systemPrompt: string[],\n    newMessageContents: LlmChatCompletionsContent[],\n    options: LlmChatCompletionsOptions,\n    inProgress?: {\n      messages: Content[];\n      toolResults?: {\n        id: string;\n        content: string;\n      }[];\n    },\n  ): Promise<LlmChatCompletionsResponse> {\n    const covertedSystemPrompt: Content = {\n      role: \"model\",\n      parts: [],\n    };\n    systemPrompt.forEach((msg) => {\n      covertedSystemPrompt.parts.push({\n        text: msg,\n      });\n    });\n    let updatedMessages: Content[] = [];\n    if (inProgress) {\n      const resParts =\n        inProgress.toolResults?.map((toolResult) => {\n          return { text: toolResult.content };\n        }) || [];\n      updatedMessages = inProgress.messages.concat({ role: \"user\", parts: resParts });\n    }\n    if (newMessageContents.length > 0) {\n      const resParts = await Promise.all(\n        newMessageContents.map(async (content) => {\n          if (content.image) {\n            const { mimeType, base64Content } = await this.convertImageUrlToBase64(content.image.url);\n            return {\n              inlineData: {\n                mimeType: mimeType,\n                data: base64Content,\n              },\n            };\n          } else {\n            return { text: content.text || \"\" };\n          }\n        }),\n      );\n      updatedMessages.push({ role: \"user\", parts: resParts });\n    }\n\n    let toolsOption = {};\n    let resFormatOption = {};\n    if (options.tools && options.tools.length > 0) {\n      toolsOption =\n        options.toolOption.type === \"function\" || options.toolOption.type === \"function_strict\"\n          ? {\n              tools: this.convertTools(options.tools),\n              toolConfig: {\n                functionCallingConfig: {\n                  mode: (String(options.toolOption.choice).toUpperCase() as FunctionCallingMode) || FunctionCallingMode.AUTO,\n                },\n              },\n            }\n          : {};\n      resFormatOption = options.toolOption.type === \"response_format\" ? this.convertResponseFormatJSONSchema(options.tools[0]) : {};\n    }\n\n    const modelParams: ModelParams = {\n      safetySettings: [\n        {\n          category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n          threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n        },\n      ],\n      generationConfig: {\n        maxOutputTokens: (options.toolOption.maxTokens as number) || 1028,\n        temperature: (options.toolOption.temperature as number) ?? 0.7,\n        ...resFormatOption,\n      },\n      model: this.llmConfig.apiModelChat,\n      systemInstruction: covertedSystemPrompt,\n      ...toolsOption,\n    };\n    let response: LlmChatCompletionsResponse = {\n      text: \"\",\n      tools: [],\n      messages: [],\n    };\n    try {\n      // For history\n      const historyMessages = this.convertMessagesForHistory(updatedMessages);\n\n      // debug\n      console.log(\"[chatCompletions] start -- historyMessages: \", JSON.stringify(historyMessages));\n\n      const chatResult = await this.geminiClient.getGenerativeModel(modelParams).generateContent({\n        contents: updatedMessages,\n      });\n      const chatResponse = chatResult.response;\n      const text = chatResponse.text();\n      const funcCalls = chatResponse.functionCalls();\n      const finishReason = chatResponse.candidates && chatResponse.candidates[0].finishReason;\n      // debug\n      console.log(`[chatCompletions] end -- response.text: ${text} response.functionCalls: ${JSON.stringify(funcCalls)} finishReason: ${finishReason}`);\n\n      let resTools: { id: string; name: string; arguments: Record<string, any> }[] = [];\n      if (chatResponse) {\n        const parts: FunctionCallPart[] = [];\n        resTools = funcCalls\n          ? funcCalls?.map((funcCall) => {\n              parts.push({ functionCall: funcCall });\n              return {\n                id: \"\",\n                name: funcCall.name,\n                arguments: JSON.parse(JSON.stringify(funcCall.args)) as Record<string, any>,\n              };\n            }) || []\n          : [];\n        historyMessages.push({ role: \"model\", parts: parts });\n      }\n\n      response = {\n        text: text,\n        tools: resTools,\n        messages: historyMessages,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[chatCompletions] Error: \", error);\n      throw error;\n    }\n\n    // debug\n    console.log(\"[chatCompletions] response: \", response);\n    return response;\n  }\n\n  async speechToText(__: string, ___?: Record<string, any>): Promise<string> {\n    //================ Not supported\n    try {\n      return \"unsupported\";\n    } catch (error) {\n      // debug\n      console.log(\"[speechToText] Error: \", error);\n      throw error;\n    }\n  }\n\n  async textToSpeech(_: string, options?: Record<string, any>): Promise<LlmTextToSpeechResponse> {\n    //================ Not supported\n    try {\n      const sorryFormat = options?.responseFormat === \"wav\" || options?.responseFormat === \"aac\" ? options.responseFormat : \"mp3\";\n      const sorry = await fs.readFile(`audio/sorry.ja.${sorryFormat}`);\n      const contentType = sorryFormat === \"mp3\" ? \"audio/mpeg\" : `audio/${sorryFormat}`;\n      return {\n        contentType: contentType,\n        content: sorry,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[textToSpeech] Error: \", error);\n      throw error;\n    }\n  }\n}\n","import { promises as fs } from \"fs\";\nimport { Groq } from \"groq-sdk\";\nimport { z } from \"zod\";\nimport { LlmAdapter } from \"@/llm_adapter\";\nimport { LlmChatCompletionsContent, LlmChatCompletionsOptions, LlmChatCompletionsResponse, LlmTextToSpeechResponse, McpTool } from \"@/llm_adapter_schemas\";\n\nexport class GroqAdapter implements LlmAdapter {\n  protected llmConfig;\n  protected groqClient;\n\n  constructor(\n    llmConfig = {\n      apiKey: JSON.parse(process.env.APP_SECRETS || \"{}\").GROQ_API_KEY || process.env.GROQ_API_KEY,\n      apiModelChat: process.env.GROQ_API_MODEL_CHAT,\n    },\n    llmConfigSchema = z.object({\n      apiKey: z.string().min(1, \"GROQ_API_KEY is required\"),\n      apiModelChat: z.string().min(1, \"GROQ_API_MODEL_CHAT is required\"),\n    }),\n  ) {\n    this.llmConfig = llmConfigSchema.parse(llmConfig);\n    this.groqClient = new Groq({ apiKey: llmConfig.apiKey });\n  }\n\n  private convertTools(tools: McpTool[]): Groq.Chat.ChatCompletionTool[] {\n    return tools.map((tool) => {\n      return {\n        type: \"function\",\n        function: {\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.inputSchema,\n        },\n      };\n    });\n  }\n\n  async chatCompletions(\n    systemPrompt: string[],\n    newMessageContents: LlmChatCompletionsContent[],\n    options: LlmChatCompletionsOptions,\n    inProgress?: {\n      messages: Groq.Chat.ChatCompletionMessageParam[];\n      toolResults?: {\n        id: string;\n        content: string;\n      }[];\n    },\n  ): Promise<LlmChatCompletionsResponse> {\n    let updatedMessages: Groq.Chat.ChatCompletionMessageParam[] = [];\n    if (inProgress) {\n      const resMessages =\n        inProgress.toolResults?.map((toolResult) => {\n          return {\n            tool_call_id: toolResult.id,\n            role: \"tool\",\n            content: toolResult.content,\n          } as Groq.Chat.ChatCompletionMessageParam;\n        }) || [];\n      updatedMessages = inProgress.messages.concat(resMessages);\n    } else {\n      // Solutions to the following issues:\n      // \"prompting with images is incompatible with system messages\"\n      const hasImage = newMessageContents.some((content) => content.image);\n      if (hasImage) {\n        updatedMessages.push({\n          role: \"user\",\n          content: systemPrompt.map((msg) => {\n            return {\n              type: \"text\",\n              text: msg,\n            };\n          }),\n        });\n      } else {\n        systemPrompt.forEach((msg) => {\n          updatedMessages.push({\n            role: \"system\",\n            content: msg,\n          });\n        });\n      }\n    }\n    if (newMessageContents.length > 0) {\n      updatedMessages.push({\n        role: \"user\",\n        content: newMessageContents.map((content) => {\n          return content.image\n            ? {\n                type: \"image_url\",\n                image_url: {\n                  url: content.image.url,\n                  detail: content.image.detail || \"auto\",\n                },\n              }\n            : {\n                type: \"text\",\n                text: content.text || \"\",\n              };\n        }),\n      });\n    }\n\n    let toolsOption = {};\n    let resFormatOption = {};\n    if (options.tools && options.tools.length > 0) {\n      toolsOption =\n        options.toolOption.type === \"function\" || options.toolOption.type === \"function_strict\"\n          ? {\n              tools: this.convertTools(options.tools),\n              tool_choice: options.toolOption.choice || (\"auto\" as Groq.Chat.ChatCompletionToolChoiceOption),\n            }\n          : {};\n      resFormatOption =\n        options.toolOption.type === \"response_format\"\n          ? {\n              response_format: {\n                type: \"json_object\",\n              } as Groq.Chat.CompletionCreateParams.ResponseFormat,\n            }\n          : {};\n    }\n\n    const chatOtions = {\n      model: this.llmConfig.apiModelChat,\n      messages: updatedMessages,\n      max_tokens: (options.toolOption.maxTokens as number) || 1028,\n      temperature: (options.toolOption.temperature as number) ?? 0.7,\n      ...toolsOption,\n      ...resFormatOption,\n    };\n    let response: LlmChatCompletionsResponse = {\n      text: \"\",\n      tools: [],\n      messages: [],\n    };\n    try {\n      // debug\n      console.log(\"[chatCompletions] start -- updatedMessages: \", JSON.stringify(updatedMessages));\n      const chatResponse = await this.groqClient.chat.completions.create(chatOtions);\n      const choice = chatResponse.choices[0];\n      const finishReason = choice.finish_reason;\n      // debug\n      console.log(`[chatCompletions] end -- choices[0].message: ${JSON.stringify(choice.message)} finishReason: ${finishReason}`);\n\n      let resTools: { id: string; name: string; arguments: Record<string, any> }[] = [];\n      if (choice.message) {\n        updatedMessages.push(choice.message);\n        resTools =\n          finishReason === \"tool_calls\"\n            ? choice.message.tool_calls?.map((tool_call) => {\n                return {\n                  id: tool_call.id,\n                  name: tool_call.function.name,\n                  arguments: JSON.parse(tool_call.function.arguments) as Record<string, any>,\n                };\n              }) || []\n            : [];\n      }\n\n      response = {\n        text: choice.message?.content,\n        tools: resTools,\n        messages: updatedMessages,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[chatCompletions] Error: \", error);\n      throw error;\n    }\n\n    // debug\n    console.log(\"[chatCompletions] response: \", response);\n    return response;\n  }\n\n  async speechToText(__: string, ___?: Record<string, any>): Promise<string> {\n    //================ Not supported\n    try {\n      return \"unsupported\";\n    } catch (error) {\n      // debug\n      console.log(\"[speechToText] Error: \", error);\n      throw error;\n    }\n  }\n\n  async textToSpeech(_: string, options?: Record<string, any>): Promise<LlmTextToSpeechResponse> {\n    //================ Not supported\n    try {\n      const sorryFormat = options?.responseFormat === \"wav\" || options?.responseFormat === \"aac\" ? options.responseFormat : \"mp3\";\n      const sorry = await fs.readFile(`audio/sorry.ja.${sorryFormat}`);\n      const contentType = sorryFormat === \"mp3\" ? \"audio/mpeg\" : `audio/${sorryFormat}`;\n      return {\n        contentType: contentType,\n        content: sorry,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[textToSpeech] Error: \", error);\n      throw error;\n    }\n  }\n}\n","import { z } from \"zod\";\n\nexport const llmChatCompletionsResponseSchema = z.object({\n  text: z.string().nullable(),\n  tools: z.array(\n    z.object({\n      id: z.string(),\n      name: z.string(),\n      arguments: z.record(z.any()),\n    }),\n  ),\n  messages: z.array(z.any()),\n});\n\nexport const llmChatCompletionsContentSchema = z.object({\n  text: z.string().optional(),\n  image: z\n    .object({\n      url: z.string(),\n      detail: z.any().optional(),\n    })\n    .optional(),\n  audio: z\n    .object({\n      data: z.string(),\n      format: z.any().optional(),\n    })\n    .optional(),\n});\n\nexport const llmChatCompletionsOptionsSchema = z.object({\n  tools: z.array(z.any()).optional(),\n  toolOption: z.object({\n    choice: z.any().optional(),\n    maxTokens: z.number().optional(),\n    temperature: z.number().optional(),\n    type: z.enum([\"function\", \"function_strict\", \"response_format\"]).optional(),\n  }),\n});\n// .catchall(z.any());\n\nexport const llmTextToSpeechResponseSchema = z.object({\n  contentType: z.string(),\n  content: z.instanceof(Buffer),\n});\n\nexport const mcpToolSchema = z.object({\n  name: z.string(),\n  description: z.string(),\n  inputSchema: z.object({\n    type: z.string(),\n    properties: z.record(z.any()),\n    required: z.array(z.string()),\n  }),\n});\n\nexport type LlmChatCompletionsResponse = z.infer<typeof llmChatCompletionsResponseSchema>;\nexport type LlmChatCompletionsContent = z.infer<typeof llmChatCompletionsContentSchema>;\nexport type LlmChatCompletionsOptions = z.infer<typeof llmChatCompletionsOptionsSchema>;\nexport type LlmTextToSpeechResponse = z.infer<typeof llmTextToSpeechResponseSchema>;\nexport type McpTool = z.infer<typeof mcpToolSchema>;\n"],"names":["OpenAIAdapter","constructor","llmConfig","apiKey","JSON","parse","process","env","APP_SECRETS","OPENAI_API_KEY","apiModelChat","OPENAI_API_MODEL_CHAT","apiModelAudioTranscription","OPENAI_API_MODEL_AUDIO_TRANSCRIPTION","apiModelText2Speech","OPENAI_API_MODEL_TEXT2SPEECH","llmConfigSchema","z","object","string","min","optional","apiClient","this","openaiClient","OpenAI","addAdditionalPropertiesElementToObjectType","schema","bool","type","additionalProperties","properties","key","items","convertTools","tools","isStrict","strict","map","tool","function","name","description","parameters","inputSchema","convertResponseFormatJSONSchema","json_schema","chatCompletions","systemPrompt","newMessageContents","options","inProgress","updatedMessages","resMessages","toolResults","toolResult","tool_call_id","id","role","content","messages","concat","forEach","msg","push","length","image","image_url","url","detail","audio","input_audio","data","format","text","toolsOption","resFormatOption","toolOption","tool_choice","choice","response_format","chatOtions","model","max_tokens","maxTokens","temperature","response","console","log","stringify","chat","completions","create","choices","finishReason","finish_reason","message","resTools","tool_calls","tool_call","arguments","error","speechToText","audioFilePath","speechOtions","file","createReadStream","language","transcriptions","textToSpeech","input","voice","responseFormat","speech","contentType","headers","get","arrayBuffer","Buffer","from","llmAdapterClasses","AzureOpenAI","AZURE_OPENAI_API_KEY","AZURE_OPENAI_API_DEPLOYMENT_CHAT","AZURE_OPENAI_API_DEPLOYMENT_AUDIO_TRANSCRIPTION","AZURE_OPENAI_API_DEPLOYMENT_TEXT2SPEECH","endpoint","AZURE_OPENAI_ENDPOINT","apiVersion","OPENAI_API_VERSION","super","Anthropic","ANTHROPIC_API_KEY","ANTHROPIC_API_MODEL_CHAT","anthropicClient","input_schema","convertImageUrlToBase64","imageUrl","fetch","buffer","mimeType","base64Content","toString","Error","convertMessagesForHistory","Array","isArray","item","source","covertedSystemPrompt","tool_use_id","list","Promise","all","async","media_type","system","historyMessages","chatResponse","contents","stopReason","stop_reason","filter","contentBlock","__","___","_","sorryFormat","sorry","fs","readFile","Google","GEMINI_API_KEY","GEMINI_API_MODEL_CHAT","geminiClient","GoogleGenerativeAI","cleanJsonSchema","cleanedSchema","Object","keys","reduce","acc","propKey","rest","functions","functionDeclarations","responseMimeType","responseSchema","parts","part","inlineData","resParts","toolConfig","functionCallingConfig","mode","String","toUpperCase","FunctionCallingMode","AUTO","modelParams","safetySettings","category","HarmCategory","HARM_CATEGORY_DANGEROUS_CONTENT","threshold","HarmBlockThreshold","BLOCK_ONLY_HIGH","generationConfig","maxOutputTokens","systemInstruction","getGenerativeModel","generateContent","funcCalls","functionCalls","candidates","funcCall","functionCall","args","Groq","GROQ_API_KEY","GROQ_API_MODEL_CHAT","groqClient","some","llmChatCompletionsResponseSchema","nullable","array","record","any","llmChatCompletionsContentSchema","llmChatCompletionsOptionsSchema","number","enum","llmTextToSpeechResponseSchema","instanceof","mcpToolSchema","required","llmId","llmAdapterClass"],"mappings":"6gBAMaA,EAIX,WAAAC,CACEC,EAAY,CACVC,OAAQC,KAAKC,MAAMC,QAAQC,IAAIC,aAAe,MAAMC,gBAAkBH,QAAQC,IAAIE,eAClFC,aAAcJ,QAAQC,IAAII,sBAC1BC,2BAA4BN,QAAQC,IAAIM,qCACxCC,oBAAqBR,QAAQC,IAAIQ,8BAEnCC,EAAkBC,EAACA,EAACC,OAAO,CACzBf,OAAQc,EAACA,EAACE,SAASC,IAAI,EAAG,8BAC1BV,aAAcO,EAACA,EAACE,SAASC,IAAI,EAAG,qCAChCR,2BAA4BK,EAACA,EAACE,SAASE,WACvCP,oBAAqBG,EAACA,EAACE,SAASE,aAElCC,GAEAC,KAAKrB,UAAYc,EAAgBX,MAAMH,GACvCqB,KAAKC,aAAeF,GAAa,IAAIG,EAAO,CAAEtB,OAAQD,EAAUC,SAG1D,0CAAAuB,CAA2CC,EAAaC,GAAgB,GAC9E,GAAsB,iBAAXD,GAAkC,OAAXA,EAChC,OAAOA,EAET,GAAoB,WAAhBA,EAAOE,OACTF,EAAOG,qBAAuBF,EAC1BD,EAAOI,YACT,IAAK,MAAMC,KAAOL,EAAOI,WACvBJ,EAAOI,WAAWC,GAAOT,KAAKG,2CAA2CC,EAAOI,WAAWC,GAAMJ,GAOvG,MAHoB,UAAhBD,EAAOE,MAAoBF,EAAOM,QACpCN,EAAOM,MAAQV,KAAKG,2CAA2CC,EAAOM,MAAOL,IAExED,EAGD,YAAAO,CAAaC,EAAkBC,GACrC,MAAMC,EAASD,EACX,CACEC,OAAQD,GAEV,CAAE,EACN,OAAOD,EAAMG,KAAKC,IACT,CACLV,KAAM,WACNW,SAAU,CACRC,KAAMF,EAAKE,KACXC,YAAaH,EAAKG,eACfL,EACHM,WAAYP,EAAWb,KAAKG,2CAA2Ca,EAAKK,aAAcR,GAAYG,EAAKK,iBAM3G,+BAAAC,CAAgCN,GACtC,MAAO,CACLV,KAAM,cACNiB,YAAa,CACXL,KAAMF,EAAKE,KACXC,YAAaH,EAAKG,YAClBL,QAAQ,EACRV,OAAQJ,KAAKG,2CAA2Ca,EAAKK,aAAa,KAKhF,qBAAMG,CACJC,EACAC,EACAC,EACAC,GAQA,IAAIC,EAAuD,GAC3D,GAAID,EAAY,CACd,MAAME,EACJF,EAAWG,aAAahB,KAAKiB,IACpB,CACLC,aAAcD,EAAWE,GACzBC,KAAM,OACNC,QAASJ,EAAWI,aAElB,GACRP,EAAkBD,EAAWS,SAASC,OAAOR,QAE7CL,EAAac,SAASC,IACpBX,EAAgBY,KAAK,CACnBN,KAAM,SACNC,QAASI,GACT,IAGFd,EAAmBgB,OAAS,GAC9Bb,EAAgBY,KAAK,CACnBN,KAAM,OACNC,QAASV,EAAmBX,KAAKqB,GACxBA,EAAQO,MACX,CACErC,KAAM,YACNsC,UAAW,CACTC,IAAKT,EAAQO,MAAME,IACnBC,OAAQV,EAAQO,MAAMG,QAAU,SAGpCV,EAAQW,MACN,CACEzC,KAAM,cACN0C,YAAa,CACXC,KAAMb,EAAQW,MAAME,KACpBC,OAAQd,EAAQW,MAAMG,QAAU,QAGpC,CACE5C,KAAM,OACN6C,KAAMf,EAAQe,MAAQ,QAMpC,IAAIC,EAAc,CAAE,EAChBC,EAAkB,CAAE,EACpB1B,EAAQf,OAASe,EAAQf,MAAM8B,OAAS,IAC1CU,EAC8B,aAA5BzB,EAAQ2B,WAAWhD,MAAmD,oBAA5BqB,EAAQ2B,WAAWhD,KACzD,CACEM,MAAOZ,KAAKW,aAAagB,EAAQf,MAAmC,oBAA5Be,EAAQ2B,WAAWhD,MAC3DiD,YAAa5B,EAAQ2B,WAAWE,QAAW,QAE7C,CAAE,EACRH,EAC8B,oBAA5B1B,EAAQ2B,WAAWhD,KACf,CACEmD,gBAAiBzD,KAAKsB,gCAAgCK,EAAQf,MAAM,KAEtE,CAAE,GAGV,MAAM8C,EAAa,CACjBC,MAAO3D,KAAKrB,UAAUQ,aACtBkD,SAAUR,EACV+B,WAAajC,EAAQ2B,WAAWO,WAAwB,KACxDC,YAAcnC,EAAQ2B,WAAWQ,aAA0B,MACxDV,KACAC,GAEL,IAAIU,EAAuC,CACzCZ,KAAM,GACNvC,MAAO,GACPyB,SAAU,IAEZ,IAEE2B,QAAQC,IAAI,+CAAgDpF,KAAKqF,UAAUrC,IAC3E,MACM2B,SADqBxD,KAAKC,aAAakE,KAAKC,YAAYC,OAAOX,IACzCY,QAAQ,GAC9BC,EAAef,EAAOgB,cAE5BR,QAAQC,IAAI,gDAAgDpF,KAAKqF,UAAUV,EAAOiB,0BAA0BF,KAE5G,IAAIG,EAA2E,GAC3ElB,EAAOiB,UACT5C,EAAgBY,KAAKe,EAAOiB,SAC5BC,EACmB,eAAjBH,GACIf,EAAOiB,QAAQE,YAAY5D,KAAK6D,IACvB,CACL1C,GAAI0C,EAAU1C,GACdhB,KAAM0D,EAAU3D,SAASC,KACzB2D,UAAWhG,KAAKC,MAAM8F,EAAU3D,SAAS4D,gBAG7C,IAGRd,EAAW,CACTZ,KAAMK,EAAOiB,SAASrC,QACtBxB,MAAO8D,EACPrC,SAAUR,GAEZ,MAAOiD,GAGP,MADAd,QAAQC,IAAI,4BAA6Ba,GACnCA,EAKR,OADAd,QAAQC,IAAI,+BAAgCF,GACrCA,EAGT,kBAAMgB,CAAaC,EAAuBrD,GACxC,MAAMsD,EAAe,CACnBC,KAAMC,EAAgBA,iBAACH,GACvBrB,MAAO3D,KAAKrB,UAAUU,4BAA8B,YACpD+F,SAAUzD,GAASyD,UAAY,MAEjC,IAEE,aADuBpF,KAAKC,aAAa8C,MAAMsC,eAAehB,OAAOY,IACrD9B,KAChB,MAAO2B,GAGP,MADAd,QAAQC,IAAI,yBAA0Ba,GAChCA,GAIV,kBAAMQ,CAAab,EAAiB9C,GAClC,MAAMsD,EAAe,CACnBtB,MAAO3D,KAAKrB,UAAUY,qBAAuB,QAC7CgG,MAAOd,EACPe,MAAO7D,GAAS6D,OAAS,QACzB/B,gBAAiB9B,GAAS8D,gBAAkB,OAE9C,IACE,MAAM1B,QAAiB/D,KAAKC,aAAa8C,MAAM2C,OAAOrB,OAAOY,GACvDU,EAAc5B,EAAS6B,QAAQC,IAAI,gBACnCC,QAAoB/B,EAAS+B,cACnC,MAAO,CACLH,YAAaA,EACbvD,QAAS2D,OAAOC,KAAKF,IAEvB,MAAOhB,GAGP,MADAd,QAAQC,IAAI,yBAA0Ba,GAChCA,IC1OZ,MAAMmB,EAA2D,CAC/D/F,OAAQzB,EACRyH,YCNI,cAAkCzH,EACtC,WAAAC,CACEC,EAAY,CACVC,OAAQC,KAAKC,MAAMC,QAAQC,IAAIC,aAAe,MAAMkH,sBAAwBpH,QAAQC,IAAImH,qBACxFhH,aAAcJ,QAAQC,IAAIoH,iCAC1B/G,2BAA4BN,QAAQC,IAAIqH,gDACxC9G,oBAAqBR,QAAQC,IAAIsH,wCACjCC,SAAUxH,QAAQC,IAAIwH,sBACtBC,WAAY1H,QAAQC,IAAI0H,oBAE1BjH,EAAkBC,EAACA,EAACC,OAAO,CACzBf,OAAQc,EAACA,EAACE,SAASC,IAAI,EAAG,oCAC1BV,aAAcO,EAACA,EAACE,SAASC,IAAI,EAAG,gDAChCR,2BAA4BK,EAACA,EAACE,SAASE,WACvCP,oBAAqBG,EAACA,EAACE,SAASE,WAChCyG,SAAU7G,EAACA,EAACE,SAASC,IAAI,EAAG,qCAC5B4G,WAAY/G,EAACA,EAACE,SAASC,IAAI,EAAG,qCAIhC8G,MAAMhI,EAAWc,EADC,IAAIyG,EAAAA,YAAY,CAAEtH,OAAQD,EAAUC,OAAQ2H,SAAU5H,EAAU4H,SAAUE,WAAY9H,EAAU8H,gBDZpHG,gBEDA,WAAAlI,CACEC,EAAY,CACVC,OAAQC,KAAKC,MAAMC,QAAQC,IAAIC,aAAe,MAAM4H,mBAAqB9H,QAAQC,IAAI6H,kBACrF1H,aAAcJ,QAAQC,IAAI8H,0BAE5BrH,EAAkBC,EAACA,EAACC,OAAO,CACzBf,OAAQc,EAACA,EAACE,SAASC,IAAI,EAAG,iCAC1BV,aAAcO,EAACA,EAACE,SAASC,IAAI,EAAG,2CAGlCG,KAAKrB,UAAYc,EAAgBX,MAAMH,GACvCqB,KAAK+G,gBAAkB,IAAIH,EAAU,CAAEhI,OAAQD,EAAUC,SAGnD,YAAA+B,CAAaC,GACnB,OAAOA,EAAMG,KAAKC,IACT,CACLE,KAAMF,EAAKE,KACXC,YAAaH,EAAKG,YAClB6F,aAAchG,EAAKK,gBAKjB,6BAAM4F,CAAwBC,GAIpC,IACE,MAAMnD,QAAiBoD,MAAMD,GACvBpB,QAAoB/B,EAAS+B,cAC7BsB,EAASrB,OAAOC,KAAKF,GAErBuB,EAAWtD,EAAS6B,QAAQC,IAAI,iBAAmB,aAEzD,MAAO,CAAEwB,WAAUC,cADGF,EAAOG,SAAS,WAEtC,MAAOzC,GACP,MAAM,IAAI0C,MAAM,qCAAqC1C,MAIjD,yBAAA2C,CAA0BpF,GAChC,OAAOA,EAAStB,KAAK0D,IAAa,CAChCtC,KAAMsC,EAAQtC,KACdC,QAASsF,MAAMC,QAAQlD,EAAQrC,SAC3BqC,EAAQrC,QAAQrB,KAAK6G,GACL,UAAdA,EAAKtH,KAAoB,IAAKsH,EAAMC,OAAQ,IAAKD,EAAKC,OAAQ5E,KAAM,aAA+C2E,IAErHnD,EAAQrC,YAIhB,qBAAMZ,CACJC,EACAC,EACAC,EACAC,GAQA,MAAMkG,EAAmD,GACzDrG,EAAac,SAASC,IACpBsF,EAAqBrF,KAAK,CACxBnC,KAAM,OACN6C,KAAMX,GACN,IAEJ,IAAIX,EAA4C,GAChD,GAAID,EAAY,CACd,MAAME,EACJF,EAAWG,aAAahB,KAAKiB,IACpB,CACL+F,YAAa/F,EAAWE,GACxB5B,KAAM,cACN8B,QAASJ,EAAWI,aAElB,GACRP,EAAkBD,EAAWS,SAASC,OAAO,CAAEH,KAAM,OAAQC,QAASN,IAExE,GAAIJ,EAAmBgB,OAAS,EAAG,CACjC,MAAMsF,QAAaC,QAAQC,IACzBxG,EAAmBX,KAAIoH,MAAO/F,IAC5B,GAAIA,EAAQO,MAAO,CACjB,MAAM0E,SAAEA,EAAQC,cAAEA,SAAwBtH,KAAKiH,wBAAwB7E,EAAQO,MAAME,KACrF,MAAO,CACLvC,KAAM,QACNuH,OAAQ,CACNvH,KAAM,SACN8H,WAAYf,EACZpE,KAAMqE,IAIV,MAAO,CACLhH,KAAM,OACN6C,KAAMf,EAAQe,MAAQ,QAK9BtB,EAAgBY,KAAK,CACnBN,KAAM,OACNC,QAAS4F,IAIb,MAAM5E,EACJzB,EAAQf,OAASe,EAAQf,MAAM8B,OAAS,EACpC,CACE9B,MAAOZ,KAAKW,aAAagB,EAAQf,OACjC2C,YAAa,CAAEjD,KAAMqB,EAAQ2B,WAAWE,QAAU,SAEpD,CAAE,EAEFE,EAA4C,CAChDC,MAAO3D,KAAKrB,UAAUQ,aACtBkD,SAAUR,EACVwG,OAAQP,EACRlE,WAAajC,EAAQ2B,WAAWO,WAAwB,KACxDC,YAAcnC,EAAQ2B,WAAWQ,aAA0B,MACxDV,GAEL,IAAIW,EAAuC,CACzCZ,KAAM,GACNvC,MAAO,GACPyB,SAAU,IAEZ,IAEE,MAAMiG,EAAkBtI,KAAKyH,0BAA0B5F,GAGvDmC,QAAQC,IACN,oDACApF,KAAKqF,UAAU4D,GACf,wBACAjJ,KAAKqF,UAAUoE,IAEjB,MAAMC,QAAqBvI,KAAK+G,gBAAgB1E,SAASgC,OAAOX,GAC1D8E,EAAWD,EAAanG,QACxBqG,EAAaF,EAAaG,YAEhC1E,QAAQC,IAAI,sCAAsCpF,KAAKqF,UAAUsE,kBAAyBC,KAE1F,IAAI/D,EAA2E,GAC3E6D,IACFD,EAAgB7F,KAAK,CACnBN,KAAMoG,EAAapG,KACnBC,QAASoG,IAEX9D,EACiB,aAAf+D,GACID,GACIG,QAAQC,GAAuC,aAAtBA,EAAatI,OACvCS,KAAK6H,IACG,CACL1G,GAAI0G,EAAa1G,GACjBhB,KAAM0H,EAAa1H,KACnB2D,UAAWhG,KAAKC,MAAMD,KAAKqF,UAAU0E,EAAarD,aAGxD,IAGRxB,EAAW,CACTZ,KACEuB,EAAShC,OAAS,GAAiC,oBAA5Bf,EAAQ2B,WAAWhD,KACtCzB,KAAKqF,UAAUQ,EAAS,GAAGG,WAC1B2D,EAAS,GAA2BrF,MAAQ,KACnDvC,MAAO8D,EACPrC,SAAUiG,GAEZ,MAAOxD,GAGP,MADAd,QAAQC,IAAI,4BAA6Ba,GACnCA,EAKR,OADAd,QAAQC,IAAI,+BAAgCF,GACrCA,EAGT,kBAAMgB,CAAa8D,EAAYC,GAE7B,IACE,MAAO,cACP,MAAOhE,GAGP,MADAd,QAAQC,IAAI,yBAA0Ba,GAChCA,GAIV,kBAAMQ,CAAayD,EAAWpH,GAE5B,IACE,MAAMqH,EAA0C,QAA5BrH,GAAS8D,gBAAwD,QAA5B9D,GAAS8D,eAA2B9D,EAAQ8D,eAAiB,MAChHwD,QAAcC,WAAGC,SAAS,kBAAkBH,KAElD,MAAO,CACLrD,YAFkC,QAAhBqD,EAAwB,aAAe,SAASA,IAGlE5G,QAAS6G,GAEX,MAAOnE,GAGP,MADAd,QAAQC,IAAI,yBAA0Ba,GAChCA,KFjNVsE,aGWA,WAAA1K,CACEC,EAAY,CACVC,OAAQC,KAAKC,MAAMC,QAAQC,IAAIC,aAAe,MAAMoK,gBAAkBtK,QAAQC,IAAIqK,eAClFlK,aAAcJ,QAAQC,IAAIsK,uBAE5B7J,EAAkBC,EAACA,EAACC,OAAO,CACzBf,OAAQc,EAACA,EAACE,SAASC,IAAI,EAAG,8BAC1BV,aAAcO,EAACA,EAACE,SAASC,IAAI,EAAG,wCAGlCG,KAAKrB,UAAYc,EAAgBX,MAAMH,GACvCqB,KAAKuJ,aAAe,IAAIC,qBAAmB7K,EAAUC,QAI/C,eAAA6K,CAAgBrJ,GACtB,GAAsB,iBAAXA,GAAkC,OAAXA,EAChC,OAAOA,EAET,GAAoB,WAAhBA,EAAOE,KAAmB,CAC5B,MAAMoJ,EAAqC,CAAE,EAgB7C,OAfAC,OAAOC,KAAKxJ,GAAQmC,SAAS9B,IACf,yBAARA,GAA0C,YAARA,IACxB,eAARA,EACFiJ,EAAclJ,WAAamJ,OAAOC,KAAKxJ,EAAOI,YAAYqJ,QACxD,CAACC,EAAKC,KAAa,IACdD,EACHC,CAACA,GAAU/J,KAAKyJ,gBAAgBrJ,EAAOI,WAAWuJ,OAEpD,CAAA,GAGFL,EAAcjJ,GAAOL,EAAOK,OAI3BiJ,EAET,GAAoB,UAAhBtJ,EAAOE,MAAoBF,EAAOM,MAAO,CAC3C,MAAMA,MAAEA,KAAUsJ,GAAS5J,EAC3B,MAAO,IACF4J,EACHtJ,MAAOV,KAAKyJ,gBAAgB/I,IAGhC,OAAON,EAGD,YAAAO,CAAaC,GACnB,MAAMqJ,EAAYrJ,EAAMG,KAAKC,IACpB,CACLE,KAAMF,EAAKE,KACXC,YAAaH,EAAKG,YAClBC,WAAYpB,KAAKyJ,gBAAgBzI,EAAKK,iBAK1C,OADA2C,QAAQC,IAAI,6BAA8BpF,KAAKqF,UAAU+F,EAAW,KAAM,IACnE,CAAC,CAAEC,qBAAsBD,IAG1B,+BAAA3I,CAAgCN,GACtC,MAAO,CACLmJ,iBAAkB,mBAClBC,eAAgBpK,KAAKyJ,gBAAgBzI,EAAKK,cAItC,6BAAM4F,CAAwBC,GAIpC,IACE,MAAMnD,QAAiBoD,MAAMD,GACvBpB,QAAoB/B,EAAS+B,cAC7BsB,EAASrB,OAAOC,KAAKF,GAErBuB,EAAWtD,EAAS6B,QAAQC,IAAI,iBAAmB,aAEzD,MAAO,CAAEwB,WAAUC,cADGF,EAAOG,SAAS,WAEtC,MAAOzC,GACP,MAAM,IAAI0C,MAAM,qCAAqC1C,MAIjD,yBAAA2C,CAA0BpF,GAChC,OAAOA,EAAStB,KAAK0D,IAAa,CAChCtC,KAAMsC,EAAQtC,KACdkI,MAAO5F,EAAQ4F,MAAMtJ,KAAKuJ,GAAUA,EAAKC,YAAYtH,KAAQ,IAAKqH,EAAMC,WAAY,IAAKD,EAAKC,WAAYtH,KAAM,aAA0BqH,QAI9I,qBAAM9I,CACJC,EACAC,EACAC,EACAC,GAQA,MAAMkG,EAAgC,CACpC3F,KAAM,QACNkI,MAAO,IAET5I,EAAac,SAASC,IACpBsF,EAAqBuC,MAAM5H,KAAK,CAC9BU,KAAMX,GACN,IAEJ,IAAIX,EAA6B,GACjC,GAAID,EAAY,CACd,MAAM4I,EACJ5I,EAAWG,aAAahB,KAAKiB,IACpB,CAAEmB,KAAMnB,EAAWI,aACtB,GACRP,EAAkBD,EAAWS,SAASC,OAAO,CAAEH,KAAM,OAAQkI,MAAOG,IAEtE,GAAI9I,EAAmBgB,OAAS,EAAG,CACjC,MAAM8H,QAAiBvC,QAAQC,IAC7BxG,EAAmBX,KAAIoH,MAAO/F,IAC5B,GAAIA,EAAQO,MAAO,CACjB,MAAM0E,SAAEA,EAAQC,cAAEA,SAAwBtH,KAAKiH,wBAAwB7E,EAAQO,MAAME,KACrF,MAAO,CACL0H,WAAY,CACVlD,SAAUA,EACVpE,KAAMqE,IAIV,MAAO,CAAEnE,KAAMf,EAAQe,MAAQ,QAIrCtB,EAAgBY,KAAK,CAAEN,KAAM,OAAQkI,MAAOG,IAG9C,IAAIpH,EAAc,CAAE,EAChBC,EAAkB,CAAE,EACpB1B,EAAQf,OAASe,EAAQf,MAAM8B,OAAS,IAC1CU,EAC8B,aAA5BzB,EAAQ2B,WAAWhD,MAAmD,oBAA5BqB,EAAQ2B,WAAWhD,KACzD,CACEM,MAAOZ,KAAKW,aAAagB,EAAQf,OACjC6J,WAAY,CACVC,sBAAuB,CACrBC,KAAOC,OAAOjJ,EAAQ2B,WAAWE,QAAQqH,eAAyCC,EAAAA,oBAAoBC,QAI5G,CAAE,EACR1H,EAA8C,oBAA5B1B,EAAQ2B,WAAWhD,KAA6BN,KAAKsB,gCAAgCK,EAAQf,MAAM,IAAM,CAAE,GAG/H,MAAMoK,EAA2B,CAC/BC,eAAgB,CACd,CACEC,SAAUC,EAAYA,aAACC,gCACvBC,UAAWC,EAAkBA,mBAACC,kBAGlCC,iBAAkB,CAChBC,gBAAkB9J,EAAQ2B,WAAWO,WAAwB,KAC7DC,YAAcnC,EAAQ2B,WAAWQ,aAA0B,MACxDT,GAELM,MAAO3D,KAAKrB,UAAUQ,aACtBuM,kBAAmB5D,KAChB1E,GAEL,IAAIW,EAAuC,CACzCZ,KAAM,GACNvC,MAAO,GACPyB,SAAU,IAEZ,IAEE,MAAMiG,EAAkBtI,KAAKyH,0BAA0B5F,GAGvDmC,QAAQC,IAAI,+CAAgDpF,KAAKqF,UAAUoE,IAE3E,MAGMC,SAHmBvI,KAAKuJ,aAAaoC,mBAAmBX,GAAaY,gBAAgB,CACzFpD,SAAU3G,KAEoBkC,SAC1BZ,EAAOoF,EAAapF,OACpB0I,EAAYtD,EAAauD,gBACzBvH,EAAegE,EAAawD,YAAcxD,EAAawD,WAAW,GAAGxH,aAE3EP,QAAQC,IAAI,2CAA2Cd,6BAAgCtE,KAAKqF,UAAU2H,oBAA4BtH,KAElI,IAAIG,EAA2E,GAC/E,GAAI6D,EAAc,CAChB,MAAM8B,EAA4B,GAClC3F,EAAWmH,GACPA,GAAW9K,KAAKiL,IACd3B,EAAM5H,KAAK,CAAEwJ,aAAcD,IACpB,CACL9J,GAAI,GACJhB,KAAM8K,EAAS9K,KACf2D,UAAWhG,KAAKC,MAAMD,KAAKqF,UAAU8H,EAASE,YAGlD,GACJ5D,EAAgB7F,KAAK,CAAEN,KAAM,QAASkI,MAAOA,IAG/CtG,EAAW,CACTZ,KAAMA,EACNvC,MAAO8D,EACPrC,SAAUiG,GAEZ,MAAOxD,GAGP,MADAd,QAAQC,IAAI,4BAA6Ba,GACnCA,EAKR,OADAd,QAAQC,IAAI,+BAAgCF,GACrCA,EAGT,kBAAMgB,CAAa8D,EAAYC,GAE7B,IACE,MAAO,cACP,MAAOhE,GAGP,MADAd,QAAQC,IAAI,yBAA0Ba,GAChCA,GAIV,kBAAMQ,CAAayD,EAAWpH,GAE5B,IACE,MAAMqH,EAA0C,QAA5BrH,GAAS8D,gBAAwD,QAA5B9D,GAAS8D,eAA2B9D,EAAQ8D,eAAiB,MAChHwD,QAAcC,WAAGC,SAAS,kBAAkBH,KAElD,MAAO,CACLrD,YAFkC,QAAhBqD,EAAwB,aAAe,SAASA,IAGlE5G,QAAS6G,GAEX,MAAOnE,GAGP,MADAd,QAAQC,IAAI,yBAA0Ba,GAChCA,KHrQVqH,WIHA,WAAAzN,CACEC,EAAY,CACVC,OAAQC,KAAKC,MAAMC,QAAQC,IAAIC,aAAe,MAAMmN,cAAgBrN,QAAQC,IAAIoN,aAChFjN,aAAcJ,QAAQC,IAAIqN,qBAE5B5M,EAAkBC,EAACA,EAACC,OAAO,CACzBf,OAAQc,EAACA,EAACE,SAASC,IAAI,EAAG,4BAC1BV,aAAcO,EAACA,EAACE,SAASC,IAAI,EAAG,sCAGlCG,KAAKrB,UAAYc,EAAgBX,MAAMH,GACvCqB,KAAKsM,WAAa,IAAIH,EAAIA,KAAC,CAAEvN,OAAQD,EAAUC,SAGzC,YAAA+B,CAAaC,GACnB,OAAOA,EAAMG,KAAKC,IACT,CACLV,KAAM,WACNW,SAAU,CACRC,KAAMF,EAAKE,KACXC,YAAaH,EAAKG,YAClBC,WAAYJ,EAAKK,iBAMzB,qBAAMG,CACJC,EACAC,EACAC,EACAC,GAQA,IAAIC,EAA0D,GAC9D,GAAID,EAAY,CACd,MAAME,EACJF,EAAWG,aAAahB,KAAKiB,IACpB,CACLC,aAAcD,EAAWE,GACzBC,KAAM,OACNC,QAASJ,EAAWI,aAElB,GACRP,EAAkBD,EAAWS,SAASC,OAAOR,OACxC,CAGYJ,EAAmB6K,MAAMnK,GAAYA,EAAQO,QAE5Dd,EAAgBY,KAAK,CACnBN,KAAM,OACNC,QAASX,EAAaV,KAAKyB,IAClB,CACLlC,KAAM,OACN6C,KAAMX,QAKZf,EAAac,SAASC,IACpBX,EAAgBY,KAAK,CACnBN,KAAM,SACNC,QAASI,GACT,IAIJd,EAAmBgB,OAAS,GAC9Bb,EAAgBY,KAAK,CACnBN,KAAM,OACNC,QAASV,EAAmBX,KAAKqB,GACxBA,EAAQO,MACX,CACErC,KAAM,YACNsC,UAAW,CACTC,IAAKT,EAAQO,MAAME,IACnBC,OAAQV,EAAQO,MAAMG,QAAU,SAGpC,CACExC,KAAM,OACN6C,KAAMf,EAAQe,MAAQ,QAMlC,IAAIC,EAAc,CAAE,EAChBC,EAAkB,CAAE,EACpB1B,EAAQf,OAASe,EAAQf,MAAM8B,OAAS,IAC1CU,EAC8B,aAA5BzB,EAAQ2B,WAAWhD,MAAmD,oBAA5BqB,EAAQ2B,WAAWhD,KACzD,CACEM,MAAOZ,KAAKW,aAAagB,EAAQf,OACjC2C,YAAa5B,EAAQ2B,WAAWE,QAAW,QAE7C,CAAE,EACRH,EAC8B,oBAA5B1B,EAAQ2B,WAAWhD,KACf,CACEmD,gBAAiB,CACfnD,KAAM,gBAGV,CAAE,GAGV,MAAMoD,EAAa,CACjBC,MAAO3D,KAAKrB,UAAUQ,aACtBkD,SAAUR,EACV+B,WAAajC,EAAQ2B,WAAWO,WAAwB,KACxDC,YAAcnC,EAAQ2B,WAAWQ,aAA0B,MACxDV,KACAC,GAEL,IAAIU,EAAuC,CACzCZ,KAAM,GACNvC,MAAO,GACPyB,SAAU,IAEZ,IAEE2B,QAAQC,IAAI,+CAAgDpF,KAAKqF,UAAUrC,IAC3E,MACM2B,SADqBxD,KAAKsM,WAAWnI,KAAKC,YAAYC,OAAOX,IACvCY,QAAQ,GAC9BC,EAAef,EAAOgB,cAE5BR,QAAQC,IAAI,gDAAgDpF,KAAKqF,UAAUV,EAAOiB,0BAA0BF,KAE5G,IAAIG,EAA2E,GAC3ElB,EAAOiB,UACT5C,EAAgBY,KAAKe,EAAOiB,SAC5BC,EACmB,eAAjBH,GACIf,EAAOiB,QAAQE,YAAY5D,KAAK6D,IACvB,CACL1C,GAAI0C,EAAU1C,GACdhB,KAAM0D,EAAU3D,SAASC,KACzB2D,UAAWhG,KAAKC,MAAM8F,EAAU3D,SAAS4D,gBAG7C,IAGRd,EAAW,CACTZ,KAAMK,EAAOiB,SAASrC,QACtBxB,MAAO8D,EACPrC,SAAUR,GAEZ,MAAOiD,GAGP,MADAd,QAAQC,IAAI,4BAA6Ba,GACnCA,EAKR,OADAd,QAAQC,IAAI,+BAAgCF,GACrCA,EAGT,kBAAMgB,CAAa8D,EAAYC,GAE7B,IACE,MAAO,cACP,MAAOhE,GAGP,MADAd,QAAQC,IAAI,yBAA0Ba,GAChCA,GAIV,kBAAMQ,CAAayD,EAAWpH,GAE5B,IACE,MAAMqH,EAA0C,QAA5BrH,GAAS8D,gBAAwD,QAA5B9D,GAAS8D,eAA2B9D,EAAQ8D,eAAiB,MAChHwD,QAAcC,WAAGC,SAAS,kBAAkBH,KAElD,MAAO,CACLrD,YAFkC,QAAhBqD,EAAwB,aAAe,SAASA,IAGlE5G,QAAS6G,GAEX,MAAOnE,GAGP,MADAd,QAAQC,IAAI,yBAA0Ba,GAChCA,MCtMC0H,EAAmC9M,EAACA,EAACC,OAAO,CACvDwD,KAAMzD,EAACA,EAACE,SAAS6M,WACjB7L,MAAOlB,EAACA,EAACgN,MACPhN,EAAAA,EAAEC,OAAO,CACPuC,GAAIxC,EAACA,EAACE,SACNsB,KAAMxB,EAACA,EAACE,SACRiF,UAAWnF,EAAAA,EAAEiN,OAAOjN,EAACA,EAACkN,UAG1BvK,SAAU3C,EAAAA,EAAEgN,MAAMhN,EAACA,EAACkN,SAGTC,EAAkCnN,EAACA,EAACC,OAAO,CACtDwD,KAAMzD,EAACA,EAACE,SAASE,WACjB6C,MAAOjD,EAAAA,EACJC,OAAO,CACNkD,IAAKnD,EAACA,EAACE,SACPkD,OAAQpD,EAACA,EAACkN,MAAM9M,aAEjBA,WACHiD,MAAOrD,EAAAA,EACJC,OAAO,CACNsD,KAAMvD,EAACA,EAACE,SACRsD,OAAQxD,EAACA,EAACkN,MAAM9M,aAEjBA,aAGQgN,EAAkCpN,EAACA,EAACC,OAAO,CACtDiB,MAAOlB,EAACA,EAACgN,MAAMhN,EAACA,EAACkN,OAAO9M,WACxBwD,WAAY5D,EAACA,EAACC,OAAO,CACnB6D,OAAQ9D,EAACA,EAACkN,MAAM9M,WAChB+D,UAAWnE,EAACA,EAACqN,SAASjN,WACtBgE,YAAapE,EAACA,EAACqN,SAASjN,WACxBQ,KAAMZ,EAAAA,EAAEsN,KAAK,CAAC,WAAY,kBAAmB,oBAAoBlN,eAKxDmN,EAAgCvN,EAACA,EAACC,OAAO,CACpDgG,YAAajG,EAACA,EAACE,SACfwC,QAAS1C,EAAAA,EAAEwN,WAAWnH,UAGXoH,EAAgBzN,EAACA,EAACC,OAAO,CACpCuB,KAAMxB,EAACA,EAACE,SACRuB,YAAazB,EAACA,EAACE,SACfyB,YAAa3B,EAACA,EAACC,OAAO,CACpBW,KAAMZ,EAACA,EAACE,SACRY,WAAYd,EAAAA,EAAEiN,OAAOjN,EAACA,EAACkN,OACvBQ,SAAU1N,EAAAA,EAAEgN,MAAMhN,EAACA,EAACE,qPLpCGyN,GAElB,IAAIC,EADarH,EAAkBoH"}