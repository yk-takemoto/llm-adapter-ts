{"version":3,"file":"bundle.cjs.js","sources":["../src/openai_adapter.ts","../src/llm_adapter_builder.ts","../src/azure_openai_adapter.ts","../src/anthropic_adapter.ts","../src/gemini_adapter.ts","../src/groq_adapter.ts","../src/llm_adapter_schemas.ts"],"sourcesContent":["import OpenAI from \"openai\";\nimport { createReadStream } from \"fs\";\nimport { LlmAdapter } from \"@/llm_adapter\";\nimport { LlmChatCompletionsContent, LlmChatCompletionsOptions, LlmChatCompletionsResponse, LlmTextToSpeechResponse, McpTool } from \"@/llm_adapter_schemas\";\n\nexport class OpenAIAdapter<T extends OpenAI> implements LlmAdapter {\n  protected openaiClient;\n\n  constructor(\n    protected llmConfig = {\n      apiKey: JSON.parse(process.env.APP_SECRETS || \"{}\").OPENAI_API_KEY || process.env.OPENAI_API_KEY || \"\",\n      apiModelChat: process.env.OPENAI_API_MODEL_CHAT!,\n      apiModelAudioTranscription: process.env.OPENAI_API_MODEL_AUDIO_TRANSCRIPTION!,\n      apiModelText2Speech: process.env.OPENAI_API_MODEL_TEXT2SPEECH!,\n    },\n    apiClient?: T,\n  ) {\n    this.initCheck(llmConfig);\n    this.openaiClient = apiClient || new OpenAI({ apiKey: llmConfig.apiKey });\n  }\n\n  private initCheck(llmConfig: Record<string, string>) {\n    for (const key of Object.keys(this.llmConfig)) {\n      if (!llmConfig[key]) {\n        throw new Error(`llmConfig.${key} is required but not set.`);\n      }\n    }\n  }\n\n  private addAdditionalPropertiesElementToObjectType(schema: any, bool: boolean = false) {\n    if (typeof schema !== \"object\" || schema === null) {\n      return schema;\n    }\n    if (schema.type === \"object\") {\n      schema.additionalProperties = bool;\n      if (schema.properties) {\n        for (const key in schema.properties) {\n          schema.properties[key] = this.addAdditionalPropertiesElementToObjectType(schema.properties[key], bool);\n        }\n      }\n    }\n    if (schema.type === \"array\" && schema.items) {\n      schema.items = this.addAdditionalPropertiesElementToObjectType(schema.items, bool);\n    }\n    return schema;\n  }\n\n  private convertTools(tools: McpTool[], isStrict?: boolean): OpenAI.ChatCompletionTool[] {\n    const strict = isStrict\n      ? {\n          strict: isStrict,\n        }\n      : {};\n    return tools.map((tool) => {\n      return {\n        type: \"function\",\n        function: {\n          name: tool.name,\n          description: tool.description,\n          ...strict,\n          parameters: isStrict ? this.addAdditionalPropertiesElementToObjectType(tool.inputSchema, !isStrict) : tool.inputSchema,\n        },\n      };\n    });\n  }\n\n  private convertResponseFormatJSONSchema(tool: McpTool): OpenAI.ResponseFormatJSONSchema {\n    return {\n      type: \"json_schema\",\n      json_schema: {\n        name: tool.name,\n        description: tool.description,\n        strict: true,\n        schema: this.addAdditionalPropertiesElementToObjectType(tool.inputSchema, false),\n      },\n    };\n  }\n\n  async chatCompletions(\n    systemPrompt: string[],\n    firstMessageContents: LlmChatCompletionsContent[],\n    options: LlmChatCompletionsOptions,\n    inProgress?: {\n      messages: OpenAI.ChatCompletionMessageParam[];\n      toolResults?: {\n        id: string;\n        content: string;\n      }[];\n    },\n  ): Promise<LlmChatCompletionsResponse> {\n    let updatedMessages: OpenAI.ChatCompletionMessageParam[] = [];\n    if (inProgress) {\n      const resMessages =\n        inProgress.toolResults?.map((toolResult) => {\n          return {\n            tool_call_id: toolResult.id,\n            role: \"tool\",\n            content: toolResult.content,\n          } as OpenAI.ChatCompletionMessageParam;\n        }) || [];\n      updatedMessages = inProgress.messages.concat(resMessages);\n    } else {\n      systemPrompt.forEach((msg) => {\n        updatedMessages.push({\n          role: \"system\",\n          content: msg,\n        });\n      });\n      updatedMessages.push({\n        role: \"user\",\n        content: firstMessageContents.map((content) => {\n          return content.image\n            ? {\n                type: \"image_url\",\n                image_url: {\n                  url: content.image.url,\n                  detail: content.image.detail || \"auto\",\n                },\n              }\n            : content.audio\n              ? {\n                  type: \"input_audio\",\n                  input_audio: {\n                    data: content.audio.data,\n                    format: content.audio.format || \"mp3\",\n                  },\n                }\n              : {\n                  type: \"text\",\n                  text: content.text || \"\",\n                };\n        }),\n      });\n    }\n\n    let toolsOption = {};\n    let resFormatOption = {};\n    if (options.tools && options.tools.length > 0) {\n      toolsOption =\n        options.purposeOfTools === \"function\"\n          ? {\n              tools: this.convertTools(options.tools, true),\n              tool_choice: options.toolChoice || (\"auto\" as OpenAI.ChatCompletionToolChoiceOption),\n            }\n          : {};\n      resFormatOption =\n        options.purposeOfTools === \"response_format\"\n          ? {\n              response_format: this.convertResponseFormatJSONSchema(options.tools[0]),\n            }\n          : {};\n    }\n\n    const chatOtions = {\n      model: this.llmConfig.apiModelChat,\n      messages: updatedMessages,\n      max_tokens: (options.maxTokens as number) || 1028,\n      temperature: (options.temperature as number) ?? 0.7,\n      ...toolsOption,\n      ...resFormatOption,\n    };\n    let response: LlmChatCompletionsResponse = {\n      text: \"\",\n      tools: [],\n      messages: [],\n    };\n    try {\n      // debug\n      console.log(\"[chatCompletions] start -- updatedMessages: \", JSON.stringify(updatedMessages));\n      const chatResponse = await this.openaiClient.chat.completions.create(chatOtions);\n      const choice = chatResponse.choices[0];\n      const finishReason = choice.finish_reason;\n      // debug\n      console.log(`[chatCompletions] end -- choices[0].message: ${JSON.stringify(choice.message)} finishReason: ${finishReason}`);\n\n      let resTools: { id: string; name: string; arguments: Record<string, any> }[] = [];\n      if (choice.message) {\n        updatedMessages.push(choice.message);\n        resTools =\n          finishReason === \"tool_calls\"\n            ? choice.message.tool_calls?.map((tool_call) => {\n                return {\n                  id: tool_call.id,\n                  name: tool_call.function.name,\n                  arguments: JSON.parse(tool_call.function.arguments) as Record<string, any>,\n                };\n              }) || []\n            : [];\n      }\n\n      response = {\n        text: choice.message?.content,\n        tools: resTools,\n        messages: updatedMessages,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[chatCompletions] Error: \", error);\n      throw error;\n    }\n\n    // debug\n    console.log(\"[chatCompletions] response: \", response);\n    return response;\n  }\n\n  async speechToText(audioFilePath: string, options?: Record<string, any>): Promise<string> {\n    const speechOtions = {\n      file: createReadStream(audioFilePath),\n      model: this.llmConfig.apiModelAudioTranscription,\n      language: options?.language || \"ja\",\n    };\n    try {\n      const response = await this.openaiClient.audio.transcriptions.create(speechOtions);\n      return response.text;\n    } catch (error) {\n      // debug\n      console.log(\"[speechToText] Error: \", error);\n      throw error;\n    }\n  }\n\n  async textToSpeech(message: string, options?: Record<string, any>): Promise<LlmTextToSpeechResponse> {\n    const speechOtions = {\n      model: this.llmConfig.apiModelText2Speech || \"tts-1\",\n      input: message,\n      voice: options?.voice || \"alloy\",\n      response_format: options?.responseFormat || \"mp3\",\n    };\n    try {\n      const response = await this.openaiClient.audio.speech.create(speechOtions);\n      const contentType = response.headers.get(\"content-type\");\n      const arrayBuffer = await response.arrayBuffer();\n      return {\n        contentType: contentType!,\n        content: Buffer.from(arrayBuffer),\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[textToSpeech] Error: \", error);\n      throw error;\n    }\n  }\n}\n","import { LlmAdapter } from \"@/llm_adapter\";\nimport { OpenAIAdapter } from \"@/openai_adapter\";\nimport { AzureOpenAIAdapter } from \"@/azure_openai_adapter\";\nimport { AnthropicAdapter } from \"@/anthropic_adapter\";\nimport { GeminiAdapter } from \"@/gemini_adapter\";\nimport { GroqAdapter } from \"@/groq_adapter\";\n\ntype LlmAdapterConstructor = new (...args: any[]) => LlmAdapter;\nconst llmAdapterClasses: Record<string, LlmAdapterConstructor> = {\n  OpenAI: OpenAIAdapter,\n  AzureOpenAI: AzureOpenAIAdapter,\n  Anthropic: AnthropicAdapter,\n  Google: GeminiAdapter,\n  Groq: GroqAdapter,\n};\n\nconst llmAdapterBuilder = (llmId: string): LlmAdapter => {\n  const llmAdapterClass = llmAdapterClasses[llmId];\n  return new llmAdapterClass();\n};\n\nexport default llmAdapterBuilder;\n","import { AzureOpenAI } from \"openai\";\nimport { OpenAIAdapter } from \"@/openai_adapter\";\n\nexport class AzureOpenAIAdapter extends OpenAIAdapter<AzureOpenAI> {\n  constructor(\n    llmConfig = {\n      apiKey: JSON.parse(process.env.APP_SECRETS || \"{}\").AZURE_OPENAI_API_KEY || process.env.AZURE_OPENAI_API_KEY || \"\",\n      apiModelChat: process.env.AZURE_OPENAI_API_DEPLOYMENT_CHAT!,\n      apiModelAudioTranscription: process.env.AZURE_OPENAI_API_DEPLOYMENT_AUDIO_TRANSCRIPTION!,\n      apiModelText2Speech: process.env.AZURE_OPENAI_API_DEPLOYMENT_TEXT2SPEECH!,\n      endpoint: process.env.AZURE_OPENAI_ENDPOINT!,\n      apiVersion: process.env.OPENAI_API_VERSION!,\n    },\n  ) {\n    const apiClient = new AzureOpenAI({ apiKey: llmConfig.apiKey, endpoint: llmConfig.endpoint, apiVersion: llmConfig.apiVersion });\n    super(llmConfig, apiClient);\n  }\n}\n","import { promises as fs } from \"fs\";\nimport Anthropic from \"@anthropic-ai/sdk\";\nimport { LlmAdapter } from \"@/llm_adapter\";\nimport { LlmChatCompletionsContent, LlmChatCompletionsOptions, LlmChatCompletionsResponse, LlmTextToSpeechResponse, McpTool } from \"@/llm_adapter_schemas\";\n\nexport class AnthropicAdapter implements LlmAdapter {\n  protected anthropicClient;\n\n  constructor(\n    protected llmConfig = {\n      apiKey: JSON.parse(process.env.APP_SECRETS || \"{}\").ANTHROPIC_API_KEY || process.env.ANTHROPIC_API_KEY || \"\",\n      apiModelChat: process.env.ANTHROPIC_API_MODEL_CHAT!,\n    },\n  ) {\n    this.initCheck(llmConfig);\n    this.anthropicClient = new Anthropic({ apiKey: llmConfig.apiKey });\n  }\n\n  private initCheck(llmConfig: Record<string, string>) {\n    for (const key of Object.keys(this.llmConfig)) {\n      if (!llmConfig[key]) {\n        throw new Error(`llmConfig.${key} is required but not set.`);\n      }\n    }\n  }\n\n  private convertTools(tools: McpTool[]): Anthropic.Tool[] {\n    return tools.map((tool) => {\n      return {\n        name: tool.name,\n        description: tool.description,\n        input_schema: tool.inputSchema as Anthropic.Tool.InputSchema,\n      };\n    });\n  }\n\n  private async convertImageUrlToBase64(imageUrl: string): Promise<{\n    mimeType: string;\n    base64Content: string;\n  }> {\n    try {\n      const response = await fetch(imageUrl);\n      const arrayBuffer = await response.arrayBuffer();\n      const buffer = Buffer.from(arrayBuffer);\n\n      const mimeType = response.headers.get(\"content-type\") || \"image/jpeg\";\n      const base64Content = buffer.toString(\"base64\");\n      return { mimeType, base64Content };\n    } catch (error) {\n      throw new Error(`Failed to fetch or convert image: ${error}`);\n    }\n  }\n\n  private convertMessagesForHistory(messages: Anthropic.MessageParam[]): Anthropic.MessageParam[] {\n    return messages.map((message) => ({\n      role: message.role,\n      content: Array.isArray(message.content)\n        ? message.content.map((item) =>\n            item.type === \"image\" ? ({ ...item, source: { ...item.source, data: \"ommitted\" } } as Anthropic.ImageBlockParam) : item,\n          )\n        : message.content,\n    }));\n  }\n\n  async chatCompletions(\n    systemPrompt: string[],\n    firstMessageContents: LlmChatCompletionsContent[],\n    options: LlmChatCompletionsOptions,\n    inProgress?: {\n      messages: Anthropic.MessageParam[];\n      toolResults?: {\n        id: string;\n        content: string;\n      }[];\n    },\n  ): Promise<LlmChatCompletionsResponse> {\n    const covertedSystemPrompt: Anthropic.TextBlockParam[] = [];\n    systemPrompt.forEach((msg) => {\n      covertedSystemPrompt.push({\n        type: \"text\",\n        text: msg,\n      });\n    });\n    let updatedMessages: Anthropic.MessageParam[] = [];\n    if (inProgress) {\n      const resMessages =\n        inProgress.toolResults?.map((toolResult) => {\n          return {\n            tool_use_id: toolResult.id,\n            type: \"tool_result\" as const,\n            content: toolResult.content,\n          } as Anthropic.ToolResultBlockParam;\n        }) || [];\n      updatedMessages = inProgress.messages.concat({ role: \"user\", content: resMessages });\n    } else {\n      const list = await Promise.all(\n        firstMessageContents.map(async (content) => {\n          if (content.image) {\n            const { mimeType, base64Content } = await this.convertImageUrlToBase64(content.image.url);\n            return {\n              type: \"image\",\n              source: {\n                type: \"base64\",\n                media_type: mimeType,\n                data: base64Content,\n              },\n            } as Anthropic.ImageBlockParam;\n          } else {\n            return {\n              type: \"text\",\n              text: content.text || \"\",\n            } as Anthropic.TextBlockParam;\n          }\n        }),\n      );\n      updatedMessages.push({\n        role: \"user\",\n        content: list,\n      });\n    }\n\n    const toolsOption =\n      options.tools && options.tools.length > 0\n        ? {\n            tools: this.convertTools(options.tools),\n            tool_choice: { type: options.toolChoice || \"auto\" } as Anthropic.ToolChoice,\n          }\n        : {};\n\n    const chatOtions: Anthropic.MessageCreateParams = {\n      model: this.llmConfig.apiModelChat,\n      messages: updatedMessages,\n      system: covertedSystemPrompt,\n      max_tokens: (options.maxTokens as number) || 1028,\n      temperature: (options.temperature as number) ?? 0.7,\n      ...toolsOption,\n    };\n    let response: LlmChatCompletionsResponse = {\n      text: \"\",\n      tools: [],\n      messages: [],\n    };\n    try {\n      // For history\n      const historyMessages = this.convertMessagesForHistory(updatedMessages);\n\n      // debug\n      console.log(\n        \"[chatCompletions] start -- covertedSystemPrompt: \",\n        JSON.stringify(covertedSystemPrompt),\n        \" -- historyMessages: \",\n        JSON.stringify(historyMessages),\n      );\n      const chatResponse = await this.anthropicClient.messages.create(chatOtions);\n      const contents = chatResponse.content;\n      const stopReason = chatResponse.stop_reason;\n      // debug\n      console.log(`[chatCompletions] end -- contents: ${JSON.stringify(contents)} stopReason: ${stopReason}`);\n\n      let resTools: { id: string; name: string; arguments: Record<string, any> }[] = [];\n      if (chatResponse) {\n        historyMessages.push({\n          role: chatResponse.role,\n          content: contents,\n        });\n        resTools =\n          stopReason === \"tool_use\"\n            ? contents\n                ?.filter((contentBlock) => contentBlock.type === \"tool_use\")\n                .map((contentBlock) => {\n                  return {\n                    id: contentBlock.id,\n                    name: contentBlock.name,\n                    arguments: JSON.parse(JSON.stringify(contentBlock.input)) as Record<string, any>,\n                  };\n                }) || []\n            : [];\n      }\n\n      response = {\n        text:\n          resTools.length > 0 && options.purposeOfTools === \"response_format\"\n            ? JSON.stringify(resTools[0].arguments)\n            : (contents[0] as Anthropic.TextBlock).text || null,\n        tools: resTools,\n        messages: historyMessages,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[chatCompletions] Error: \", error);\n      throw error;\n    }\n\n    // debug\n    console.log(\"[chatCompletions] response: \", response);\n    return response;\n  }\n\n  async speechToText(__: string, ___?: Record<string, any>): Promise<string> {\n    //================ Not supported\n    try {\n      return \"unsupported\";\n    } catch (error) {\n      // debug\n      console.log(\"[speechToText] Error: \", error);\n      throw error;\n    }\n  }\n\n  async textToSpeech(_: string, options?: Record<string, any>): Promise<LlmTextToSpeechResponse> {\n    //================ Not supported\n    try {\n      const sorryFormat = options?.responseFormat === \"wav\" || options?.responseFormat === \"aac\" ? options.responseFormat : \"mp3\";\n      const sorry = await fs.readFile(`audio/sorry.ja.${sorryFormat}`);\n      const contentType = sorryFormat === \"mp3\" ? \"audio/mpeg\" : `audio/${sorryFormat}`;\n      return {\n        contentType: contentType,\n        content: sorry,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[textToSpeech] Error: \", error);\n      throw error;\n    }\n  }\n}\n","import { promises as fs } from \"fs\";\nimport {\n  GoogleGenerativeAI,\n  HarmBlockThreshold,\n  HarmCategory,\n  ModelParams,\n  Content,\n  FunctionDeclaration,\n  Tool,\n  FunctionCallingMode,\n  FunctionCallPart,\n  GenerationConfig,\n  ResponseSchema,\n  Part,\n} from \"@google/generative-ai\";\nimport { LlmAdapter } from \"@/llm_adapter\";\nimport { LlmChatCompletionsContent, LlmChatCompletionsOptions, LlmChatCompletionsResponse, LlmTextToSpeechResponse, McpTool } from \"@/llm_adapter_schemas\";\n\nexport class GeminiAdapter implements LlmAdapter {\n  protected geminiClient;\n\n  constructor(\n    protected llmConfig = {\n      apiKey: JSON.parse(process.env.APP_SECRETS || \"{}\").GEMINI_API_KEY || process.env.GEMINI_API_KEY || \"\",\n      apiModelChat: process.env.GEMINI_API_MODEL_CHAT!,\n    },\n  ) {\n    this.initCheck(llmConfig);\n    this.geminiClient = new GoogleGenerativeAI(llmConfig.apiKey);\n  }\n\n  private initCheck(llmConfig: Record<string, string>) {\n    for (const key of Object.keys(this.llmConfig)) {\n      if (!llmConfig[key]) {\n        throw new Error(`llmConfig.${key} is required but not set.`);\n      }\n    }\n  }\n\n  // A function to delete parameters such as additionalProperties because the GeminiAPI tool schema does not support jsonSchema7.\n  private cleanJsonSchema(schema: Record<string, any>): Record<string, any> {\n    if (typeof schema !== \"object\" || schema === null) {\n      return schema;\n    }\n    if (schema.type === \"object\") {\n      const cleanedSchema: Record<string, any> = {};\n      Object.keys(schema).forEach((key) => {\n        if (key !== \"additionalProperties\" && key !== \"$schema\") {\n          if (key === \"properties\") {\n            cleanedSchema.properties = Object.keys(schema.properties).reduce(\n              (acc, propKey) => ({\n                ...acc,\n                [propKey]: this.cleanJsonSchema(schema.properties[propKey]),\n              }),\n              {},\n            );\n          } else {\n            cleanedSchema[key] = schema[key];\n          }\n        }\n      });\n      return cleanedSchema;\n    }\n    if (schema.type === \"array\" && schema.items) {\n      const { items, ...rest } = schema;\n      return {\n        ...rest,\n        items: this.cleanJsonSchema(items),\n      };\n    }\n    return schema;\n  }\n\n  private convertTools(tools: McpTool[]): Tool[] {\n    const functions = tools.map((tool) => {\n      return {\n        name: tool.name,\n        description: tool.description,\n        parameters: this.cleanJsonSchema(tool.inputSchema),\n      } as FunctionDeclaration;\n    });\n    // debug\n    console.log(\"[convertTools] functions: \", JSON.stringify(functions, null, 2));\n    return [{ functionDeclarations: functions }];\n  }\n\n  private convertResponseFormatJSONSchema(tool: McpTool): GenerationConfig {\n    return {\n      responseMimeType: \"application/json\",\n      responseSchema: this.cleanJsonSchema(tool.inputSchema) as ResponseSchema,\n    };\n  }\n\n  private async convertImageUrlToBase64(imageUrl: string): Promise<{\n    mimeType: string;\n    base64Content: string;\n  }> {\n    try {\n      const response = await fetch(imageUrl);\n      const arrayBuffer = await response.arrayBuffer();\n      const buffer = Buffer.from(arrayBuffer);\n\n      const mimeType = response.headers.get(\"content-type\") || \"image/jpeg\";\n      const base64Content = buffer.toString(\"base64\");\n      return { mimeType, base64Content };\n    } catch (error) {\n      throw new Error(`Failed to fetch or convert image: ${error}`);\n    }\n  }\n\n  private convertMessagesForHistory(messages: Content[]): Content[] {\n    return messages.map((message) => ({\n      role: message.role,\n      parts: message.parts.map((part) => (part.inlineData?.data ? ({ ...part, inlineData: { ...part.inlineData, data: \"ommitted\" } } as Part) : part)),\n    }));\n  }\n\n  async chatCompletions(\n    systemPrompt: string[],\n    firstMessageContents: LlmChatCompletionsContent[],\n    options: LlmChatCompletionsOptions,\n    inProgress?: {\n      messages: Content[];\n      toolResults?: {\n        id: string;\n        content: string;\n      }[];\n    },\n  ): Promise<LlmChatCompletionsResponse> {\n    const covertedSystemPrompt: Content = {\n      role: \"model\",\n      parts: [],\n    };\n    systemPrompt.forEach((msg) => {\n      covertedSystemPrompt.parts.push({\n        text: msg,\n      });\n    });\n    let updatedMessages: Content[] = [];\n    if (inProgress) {\n      const resParts =\n        inProgress.toolResults?.map((toolResult) => {\n          return { text: toolResult.content };\n        }) || [];\n      updatedMessages = inProgress.messages.concat({ role: \"user\", parts: resParts });\n    } else {\n      const resParts = await Promise.all(\n        firstMessageContents.map(async (content) => {\n          if (content.image) {\n            const { mimeType, base64Content } = await this.convertImageUrlToBase64(content.image.url);\n            return {\n              inlineData: {\n                mimeType: mimeType,\n                data: base64Content,\n              },\n            };\n          } else {\n            return { text: content.text || \"\" };\n          }\n        }),\n      );\n      updatedMessages.push({ role: \"user\", parts: resParts });\n    }\n\n    let toolsOption = {};\n    let resFormatOption = {};\n    if (options.tools && options.tools.length > 0) {\n      toolsOption =\n        options.purposeOfTools === \"function\"\n          ? {\n              tools: this.convertTools(options.tools),\n              toolConfig: {\n                functionCallingConfig: {\n                  mode: (String(options.toolChoice).toUpperCase() as FunctionCallingMode) || FunctionCallingMode.AUTO,\n                },\n              },\n            }\n          : {};\n      resFormatOption = options.purposeOfTools === \"response_format\" ? this.convertResponseFormatJSONSchema(options.tools[0]) : {};\n    }\n\n    const modelParams: ModelParams = {\n      safetySettings: [\n        {\n          category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n          threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n        },\n      ],\n      generationConfig: {\n        maxOutputTokens: (options.maxTokens as number) || 1028,\n        temperature: (options.temperature as number) ?? 0.7,\n        ...resFormatOption,\n      },\n      model: this.llmConfig.apiModelChat,\n      systemInstruction: covertedSystemPrompt,\n      ...toolsOption,\n    };\n    let response: LlmChatCompletionsResponse = {\n      text: \"\",\n      tools: [],\n      messages: [],\n    };\n    try {\n      // For history\n      const historyMessages = this.convertMessagesForHistory(updatedMessages);\n\n      // debug\n      console.log(\"[chatCompletions] start -- historyMessages: \", JSON.stringify(historyMessages));\n\n      const chatResult = await this.geminiClient.getGenerativeModel(modelParams).generateContent({\n        contents: updatedMessages,\n      });\n      const chatResponse = chatResult.response;\n      const text = chatResponse.text();\n      const funcCalls = chatResponse.functionCalls();\n      const finishReason = chatResponse.candidates && chatResponse.candidates[0].finishReason;\n      // debug\n      console.log(`[chatCompletions] end -- response.text: ${text} response.functionCalls: ${JSON.stringify(funcCalls)} finishReason: ${finishReason}`);\n\n      let resTools: { id: string; name: string; arguments: Record<string, any> }[] = [];\n      if (chatResponse) {\n        const parts: FunctionCallPart[] = [];\n        resTools = funcCalls\n          ? funcCalls?.map((funcCall) => {\n              parts.push({ functionCall: funcCall });\n              return {\n                id: \"\",\n                name: funcCall.name,\n                arguments: JSON.parse(JSON.stringify(funcCall.args)) as Record<string, any>,\n              };\n            }) || []\n          : [];\n        historyMessages.push({ role: \"model\", parts: parts });\n      }\n\n      response = {\n        text: text,\n        tools: resTools,\n        messages: historyMessages,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[chatCompletions] Error: \", error);\n      throw error;\n    }\n\n    // debug\n    console.log(\"[chatCompletions] response: \", response);\n    return response;\n  }\n\n  async speechToText(__: string, ___?: Record<string, any>): Promise<string> {\n    //================ Not supported\n    try {\n      return \"unsupported\";\n    } catch (error) {\n      // debug\n      console.log(\"[speechToText] Error: \", error);\n      throw error;\n    }\n  }\n\n  async textToSpeech(_: string, options?: Record<string, any>): Promise<LlmTextToSpeechResponse> {\n    //================ Not supported\n    try {\n      const sorryFormat = options?.responseFormat === \"wav\" || options?.responseFormat === \"aac\" ? options.responseFormat : \"mp3\";\n      const sorry = await fs.readFile(`audio/sorry.ja.${sorryFormat}`);\n      const contentType = sorryFormat === \"mp3\" ? \"audio/mpeg\" : `audio/${sorryFormat}`;\n      return {\n        contentType: contentType,\n        content: sorry,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[textToSpeech] Error: \", error);\n      throw error;\n    }\n  }\n}\n","import { promises as fs } from \"fs\";\nimport { Groq } from \"groq-sdk\";\nimport { LlmAdapter } from \"@/llm_adapter\";\nimport { LlmChatCompletionsContent, LlmChatCompletionsOptions, LlmChatCompletionsResponse, LlmTextToSpeechResponse, McpTool } from \"@/llm_adapter_schemas\";\n\nexport class GroqAdapter implements LlmAdapter {\n  protected groqClient;\n\n  constructor(\n    protected llmConfig = {\n      apiKey: JSON.parse(process.env.APP_SECRETS || \"{}\").GROQ_API_KEY || process.env.GROQ_API_KEY || \"\",\n      apiModelChat: process.env.GROQ_API_MODEL_CHAT!,\n    },\n  ) {\n    this.initCheck(llmConfig);\n    this.groqClient = new Groq({ apiKey: llmConfig.apiKey });\n  }\n\n  private initCheck(llmConfig: Record<string, string>) {\n    for (const key of Object.keys(this.llmConfig)) {\n      if (!llmConfig[key]) {\n        throw new Error(`llmConfig.${key} is required but not set.`);\n      }\n    }\n  }\n\n  private convertTools(tools: McpTool[]): Groq.Chat.ChatCompletionTool[] {\n    return tools.map((tool) => {\n      return {\n        type: \"function\",\n        function: {\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.inputSchema,\n        },\n      };\n    });\n  }\n\n  async chatCompletions(\n    systemPrompt: string[],\n    firstMessageContents: LlmChatCompletionsContent[],\n    options: LlmChatCompletionsOptions,\n    inProgress?: {\n      messages: Groq.Chat.ChatCompletionMessageParam[];\n      toolResults?: {\n        id: string;\n        content: string;\n      }[];\n    },\n  ): Promise<LlmChatCompletionsResponse> {\n    let updatedMessages: Groq.Chat.ChatCompletionMessageParam[] = [];\n    if (inProgress) {\n      const resMessages =\n        inProgress.toolResults?.map((toolResult) => {\n          return {\n            tool_call_id: toolResult.id,\n            role: \"tool\",\n            content: toolResult.content,\n          } as Groq.Chat.ChatCompletionMessageParam;\n        }) || [];\n      updatedMessages = inProgress.messages.concat(resMessages);\n    } else {\n      // Solutions to the following issues:\n      // \"prompting with images is incompatible with system messages\"\n      const hasImage = firstMessageContents.some((content) => content.image);\n      if (hasImage) {\n        updatedMessages.push({\n          role: \"user\",\n          content: systemPrompt.map((msg) => {\n            return {\n              type: \"text\",\n              text: msg,\n            };\n          }),\n        });\n      } else {\n        systemPrompt.forEach((msg) => {\n          updatedMessages.push({\n            role: \"system\",\n            content: msg,\n          });\n        });\n      }\n\n      updatedMessages.push({\n        role: \"user\",\n        content: firstMessageContents.map((content) => {\n          return content.image\n            ? {\n                type: \"image_url\",\n                image_url: {\n                  url: content.image.url,\n                  detail: content.image.detail || \"auto\",\n                },\n              }\n            : {\n                type: \"text\",\n                text: content.text || \"\",\n              };\n        }),\n      });\n    }\n\n    let toolsOption = {};\n    let resFormatOption = {};\n    if (options.tools && options.tools.length > 0) {\n      toolsOption =\n        options.purposeOfTools === \"function\"\n          ? {\n              tools: this.convertTools(options.tools),\n              tool_choice: options.toolChoice || (\"auto\" as Groq.Chat.ChatCompletionToolChoiceOption),\n            }\n          : {};\n      resFormatOption =\n        options.purposeOfTools === \"response_format\"\n          ? {\n              response_format: {\n                type: \"json_object\",\n              } as Groq.Chat.CompletionCreateParams.ResponseFormat,\n            }\n          : {};\n    }\n\n    const chatOtions = {\n      model: this.llmConfig.apiModelChat,\n      messages: updatedMessages,\n      max_tokens: (options.maxTokens as number) || 1028,\n      temperature: (options.temperature as number) ?? 0.7,\n      ...toolsOption,\n      ...resFormatOption,\n    };\n    let response: LlmChatCompletionsResponse = {\n      text: \"\",\n      tools: [],\n      messages: [],\n    };\n    try {\n      // debug\n      console.log(\"[chatCompletions] start -- updatedMessages: \", JSON.stringify(updatedMessages));\n      const chatResponse = await this.groqClient.chat.completions.create(chatOtions);\n      const choice = chatResponse.choices[0];\n      const finishReason = choice.finish_reason;\n      // debug\n      console.log(`[chatCompletions] end -- choices[0].message: ${JSON.stringify(choice.message)} finishReason: ${finishReason}`);\n\n      let resTools: { id: string; name: string; arguments: Record<string, any> }[] = [];\n      if (choice.message) {\n        updatedMessages.push(choice.message);\n        resTools =\n          finishReason === \"tool_calls\"\n            ? choice.message.tool_calls?.map((tool_call) => {\n                return {\n                  id: tool_call.id,\n                  name: tool_call.function.name,\n                  arguments: JSON.parse(tool_call.function.arguments) as Record<string, any>,\n                };\n              }) || []\n            : [];\n      }\n\n      response = {\n        text: choice.message?.content,\n        tools: resTools,\n        messages: updatedMessages,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[chatCompletions] Error: \", error);\n      throw error;\n    }\n\n    // debug\n    console.log(\"[chatCompletions] response: \", response);\n    return response;\n  }\n\n  async speechToText(__: string, ___?: Record<string, any>): Promise<string> {\n    //================ Not supported\n    try {\n      return \"unsupported\";\n    } catch (error) {\n      // debug\n      console.log(\"[speechToText] Error: \", error);\n      throw error;\n    }\n  }\n\n  async textToSpeech(_: string, options?: Record<string, any>): Promise<LlmTextToSpeechResponse> {\n    //================ Not supported\n    try {\n      const sorryFormat = options?.responseFormat === \"wav\" || options?.responseFormat === \"aac\" ? options.responseFormat : \"mp3\";\n      const sorry = await fs.readFile(`audio/sorry.ja.${sorryFormat}`);\n      const contentType = sorryFormat === \"mp3\" ? \"audio/mpeg\" : `audio/${sorryFormat}`;\n      return {\n        contentType: contentType,\n        content: sorry,\n      };\n    } catch (error) {\n      // debug\n      console.log(\"[textToSpeech] Error: \", error);\n      throw error;\n    }\n  }\n}\n","import { z } from \"zod\";\n\nexport const llmChatCompletionsResponseSchema = z.object({\n  text: z.string().nullable(),\n  tools: z.array(\n    z.object({\n      id: z.string(),\n      name: z.string(),\n      arguments: z.record(z.any()),\n    }),\n  ),\n  messages: z.array(z.any()),\n});\n\nexport const llmChatCompletionsContentSchema = z.object({\n  text: z.string().optional(),\n  image: z\n    .object({\n      url: z.string(),\n      detail: z.any().optional(),\n    })\n    .optional(),\n  audio: z\n    .object({\n      data: z.string(),\n      format: z.any().optional(),\n    })\n    .optional(),\n});\n\nexport const llmChatCompletionsOptionsSchema = z\n  .object({\n    tools: z.array(z.any()).optional(),\n    toolChoice: z.any().optional(),\n    purposeOfTools: z.enum([\"function\", \"response_format\"]).optional(),\n  })\n  .catchall(z.any());\n\nexport const llmTextToSpeechResponseSchema = z.object({\n  contentType: z.string(),\n  content: z.instanceof(Buffer),\n});\n\nexport const mcpToolSchema = z.object({\n  name: z.string(),\n  description: z.string(),\n  inputSchema: z.object({\n    type: z.string(),\n    properties: z.record(z.any()),\n    required: z.array(z.string()),\n  }),\n});\n\nexport type LlmChatCompletionsResponse = z.infer<typeof llmChatCompletionsResponseSchema>;\nexport type LlmChatCompletionsContent = z.infer<typeof llmChatCompletionsContentSchema>;\nexport type LlmChatCompletionsOptions = z.infer<typeof llmChatCompletionsOptionsSchema>;\nexport type LlmTextToSpeechResponse = z.infer<typeof llmTextToSpeechResponseSchema>;\nexport type McpTool = z.infer<typeof mcpToolSchema>;\n"],"names":["OpenAIAdapter","constructor","llmConfig","apiKey","JSON","parse","process","env","APP_SECRETS","OPENAI_API_KEY","apiModelChat","OPENAI_API_MODEL_CHAT","apiModelAudioTranscription","OPENAI_API_MODEL_AUDIO_TRANSCRIPTION","apiModelText2Speech","OPENAI_API_MODEL_TEXT2SPEECH","apiClient","this","initCheck","openaiClient","OpenAI","key","Object","keys","Error","addAdditionalPropertiesElementToObjectType","schema","bool","type","additionalProperties","properties","items","convertTools","tools","isStrict","strict","map","tool","function","name","description","parameters","inputSchema","convertResponseFormatJSONSchema","json_schema","chatCompletions","systemPrompt","firstMessageContents","options","inProgress","updatedMessages","resMessages","toolResults","toolResult","tool_call_id","id","role","content","messages","concat","forEach","msg","push","image","image_url","url","detail","audio","input_audio","data","format","text","toolsOption","resFormatOption","length","purposeOfTools","tool_choice","toolChoice","response_format","chatOtions","model","max_tokens","maxTokens","temperature","response","console","log","stringify","choice","chat","completions","create","choices","finishReason","finish_reason","message","resTools","tool_calls","tool_call","arguments","error","speechToText","audioFilePath","speechOtions","file","createReadStream","language","transcriptions","textToSpeech","input","voice","responseFormat","speech","contentType","headers","get","arrayBuffer","Buffer","from","llmAdapterClasses","AzureOpenAI","AZURE_OPENAI_API_KEY","AZURE_OPENAI_API_DEPLOYMENT_CHAT","AZURE_OPENAI_API_DEPLOYMENT_AUDIO_TRANSCRIPTION","AZURE_OPENAI_API_DEPLOYMENT_TEXT2SPEECH","endpoint","AZURE_OPENAI_ENDPOINT","apiVersion","OPENAI_API_VERSION","super","Anthropic","ANTHROPIC_API_KEY","ANTHROPIC_API_MODEL_CHAT","anthropicClient","input_schema","convertImageUrlToBase64","imageUrl","fetch","buffer","mimeType","base64Content","toString","convertMessagesForHistory","Array","isArray","item","source","covertedSystemPrompt","tool_use_id","list","Promise","all","async","media_type","system","historyMessages","chatResponse","contents","stopReason","stop_reason","filter","contentBlock","__","___","_","sorryFormat","sorry","fs","readFile","Google","GEMINI_API_KEY","GEMINI_API_MODEL_CHAT","geminiClient","GoogleGenerativeAI","cleanJsonSchema","cleanedSchema","reduce","acc","propKey","rest","functions","functionDeclarations","responseMimeType","responseSchema","parts","part","inlineData","resParts","toolConfig","functionCallingConfig","mode","String","toUpperCase","FunctionCallingMode","AUTO","modelParams","safetySettings","category","HarmCategory","HARM_CATEGORY_DANGEROUS_CONTENT","threshold","HarmBlockThreshold","BLOCK_ONLY_HIGH","generationConfig","maxOutputTokens","systemInstruction","getGenerativeModel","generateContent","funcCalls","functionCalls","candidates","funcCall","functionCall","args","Groq","GROQ_API_KEY","GROQ_API_MODEL_CHAT","groqClient","some","llmChatCompletionsResponseSchema","z","object","string","nullable","array","record","any","llmChatCompletionsContentSchema","optional","llmChatCompletionsOptionsSchema","enum","catchall","llmTextToSpeechResponseSchema","instanceof","mcpToolSchema","required","llmId","llmAdapterClass"],"mappings":"oKAKaA,EAGX,WAAAC,CACYC,EAAY,CACpBC,OAAQC,KAAKC,MAAMC,QAAQC,IAAIC,aAAe,MAAMC,gBAAkBH,QAAQC,IAAIE,gBAAkB,GACpGC,aAAcJ,QAAQC,IAAII,sBAC1BC,2BAA4BN,QAAQC,IAAIM,qCACxCC,oBAAqBR,QAAQC,IAAIQ,8BAEnCC,GANUC,KAASf,UAATA,EAQVe,KAAKC,UAAUhB,GACfe,KAAKE,aAAeH,GAAa,IAAII,EAAO,CAAEjB,OAAQD,EAAUC,SAG1D,SAAAe,CAAUhB,GAChB,IAAK,MAAMmB,KAAOC,OAAOC,KAAKN,KAAKf,WACjC,IAAKA,EAAUmB,GACb,MAAM,IAAIG,MAAM,aAAaH,8BAK3B,0CAAAI,CAA2CC,EAAaC,GAAgB,GAC9E,GAAsB,iBAAXD,GAAkC,OAAXA,EAChC,OAAOA,EAET,GAAoB,WAAhBA,EAAOE,OACTF,EAAOG,qBAAuBF,EAC1BD,EAAOI,YACT,IAAK,MAAMT,KAAOK,EAAOI,WACvBJ,EAAOI,WAAWT,GAAOJ,KAAKQ,2CAA2CC,EAAOI,WAAWT,GAAMM,GAOvG,MAHoB,UAAhBD,EAAOE,MAAoBF,EAAOK,QACpCL,EAAOK,MAAQd,KAAKQ,2CAA2CC,EAAOK,MAAOJ,IAExED,EAGD,YAAAM,CAAaC,EAAkBC,GACrC,MAAMC,EAASD,EACX,CACEC,OAAQD,GAEV,CAAE,EACN,OAAOD,EAAMG,KAAKC,IACT,CACLT,KAAM,WACNU,SAAU,CACRC,KAAMF,EAAKE,KACXC,YAAaH,EAAKG,eACfL,EACHM,WAAYP,EAAWjB,KAAKQ,2CAA2CY,EAAKK,aAAcR,GAAYG,EAAKK,iBAM3G,+BAAAC,CAAgCN,GACtC,MAAO,CACLT,KAAM,cACNgB,YAAa,CACXL,KAAMF,EAAKE,KACXC,YAAaH,EAAKG,YAClBL,QAAQ,EACRT,OAAQT,KAAKQ,2CAA2CY,EAAKK,aAAa,KAKhF,qBAAMG,CACJC,EACAC,EACAC,EACAC,GAQA,IAAIC,EAAuD,GAC3D,GAAID,EAAY,CACd,MAAME,EACJF,EAAWG,aAAahB,KAAKiB,IACpB,CACLC,aAAcD,EAAWE,GACzBC,KAAM,OACNC,QAASJ,EAAWI,aAElB,GACRP,EAAkBD,EAAWS,SAASC,OAAOR,QAE7CL,EAAac,SAASC,IACpBX,EAAgBY,KAAK,CACnBN,KAAM,SACNC,QAASI,GACT,IAEJX,EAAgBY,KAAK,CACnBN,KAAM,OACNC,QAASV,EAAqBX,KAAKqB,GAC1BA,EAAQM,MACX,CACEnC,KAAM,YACNoC,UAAW,CACTC,IAAKR,EAAQM,MAAME,IACnBC,OAAQT,EAAQM,MAAMG,QAAU,SAGpCT,EAAQU,MACN,CACEvC,KAAM,cACNwC,YAAa,CACXC,KAAMZ,EAAQU,MAAME,KACpBC,OAAQb,EAAQU,MAAMG,QAAU,QAGpC,CACE1C,KAAM,OACN2C,KAAMd,EAAQc,MAAQ,QAMpC,IAAIC,EAAc,CAAE,EAChBC,EAAkB,CAAE,EACpBzB,EAAQf,OAASe,EAAQf,MAAMyC,OAAS,IAC1CF,EAC6B,aAA3BxB,EAAQ2B,eACJ,CACE1C,MAAOhB,KAAKe,aAAagB,EAAQf,OAAO,GACxC2C,YAAa5B,EAAQ6B,YAAe,QAEtC,CAAE,EACRJ,EAC6B,oBAA3BzB,EAAQ2B,eACJ,CACEG,gBAAiB7D,KAAK0B,gCAAgCK,EAAQf,MAAM,KAEtE,CAAE,GAGV,MAAM8C,EAAa,CACjBC,MAAO/D,KAAKf,UAAUQ,aACtBgD,SAAUR,EACV+B,WAAajC,EAAQkC,WAAwB,KAC7CC,YAAcnC,EAAQmC,aAA0B,MAC7CX,KACAC,GAEL,IAAIW,EAAuC,CACzCb,KAAM,GACNtC,MAAO,GACPyB,SAAU,IAEZ,IAEE2B,QAAQC,IAAI,+CAAgDlF,KAAKmF,UAAUrC,IAC3E,MACMsC,SADqBvE,KAAKE,aAAasE,KAAKC,YAAYC,OAAOZ,IACzCa,QAAQ,GAC9BC,EAAeL,EAAOM,cAE5BT,QAAQC,IAAI,gDAAgDlF,KAAKmF,UAAUC,EAAOO,0BAA0BF,KAE5G,IAAIG,EAA2E,GAC3ER,EAAOO,UACT7C,EAAgBY,KAAK0B,EAAOO,SAC5BC,EACmB,eAAjBH,GACIL,EAAOO,QAAQE,YAAY7D,KAAK8D,IACvB,CACL3C,GAAI2C,EAAU3C,GACdhB,KAAM2D,EAAU5D,SAASC,KACzB4D,UAAW/F,KAAKC,MAAM6F,EAAU5D,SAAS6D,gBAG7C,IAGRf,EAAW,CACTb,KAAMiB,EAAOO,SAAStC,QACtBxB,MAAO+D,EACPtC,SAAUR,GAEZ,MAAOkD,GAGP,MADAf,QAAQC,IAAI,4BAA6Bc,GACnCA,EAKR,OADAf,QAAQC,IAAI,+BAAgCF,GACrCA,EAGT,kBAAMiB,CAAaC,EAAuBtD,GACxC,MAAMuD,EAAe,CACnBC,KAAMC,EAAgBA,iBAACH,GACvBtB,MAAO/D,KAAKf,UAAUU,2BACtB8F,SAAU1D,GAAS0D,UAAY,MAEjC,IAEE,aADuBzF,KAAKE,aAAagD,MAAMwC,eAAehB,OAAOY,IACrDhC,KAChB,MAAO6B,GAGP,MADAf,QAAQC,IAAI,yBAA0Bc,GAChCA,GAIV,kBAAMQ,CAAab,EAAiB/C,GAClC,MAAMuD,EAAe,CACnBvB,MAAO/D,KAAKf,UAAUY,qBAAuB,QAC7C+F,MAAOd,EACPe,MAAO9D,GAAS8D,OAAS,QACzBhC,gBAAiB9B,GAAS+D,gBAAkB,OAE9C,IACE,MAAM3B,QAAiBnE,KAAKE,aAAagD,MAAM6C,OAAOrB,OAAOY,GACvDU,EAAc7B,EAAS8B,QAAQC,IAAI,gBACnCC,QAAoBhC,EAASgC,cACnC,MAAO,CACLH,YAAaA,EACbxD,QAAS4D,OAAOC,KAAKF,IAEvB,MAAOhB,GAGP,MADAf,QAAQC,IAAI,yBAA0Bc,GAChCA,ICxOZ,MAAMmB,EAA2D,CAC/DnG,OAAQpB,EACRwH,YCPI,cAAkCxH,EACtC,WAAAC,CACEC,EAAY,CACVC,OAAQC,KAAKC,MAAMC,QAAQC,IAAIC,aAAe,MAAMiH,sBAAwBnH,QAAQC,IAAIkH,sBAAwB,GAChH/G,aAAcJ,QAAQC,IAAImH,iCAC1B9G,2BAA4BN,QAAQC,IAAIoH,gDACxC7G,oBAAqBR,QAAQC,IAAIqH,wCACjCC,SAAUvH,QAAQC,IAAIuH,sBACtBC,WAAYzH,QAAQC,IAAIyH,qBAI1BC,MAAM/H,EADY,IAAIsH,EAAAA,YAAY,CAAErH,OAAQD,EAAUC,OAAQ0H,SAAU3H,EAAU2H,SAAUE,WAAY7H,EAAU6H,gBDHpHG,gBEHA,WAAAjI,CACYC,EAAY,CACpBC,OAAQC,KAAKC,MAAMC,QAAQC,IAAIC,aAAe,MAAM2H,mBAAqB7H,QAAQC,IAAI4H,mBAAqB,GAC1GzH,aAAcJ,QAAQC,IAAI6H,2BAFlBnH,KAASf,UAATA,EAKVe,KAAKC,UAAUhB,GACfe,KAAKoH,gBAAkB,IAAIH,EAAU,CAAE/H,OAAQD,EAAUC,SAGnD,SAAAe,CAAUhB,GAChB,IAAK,MAAMmB,KAAOC,OAAOC,KAAKN,KAAKf,WACjC,IAAKA,EAAUmB,GACb,MAAM,IAAIG,MAAM,aAAaH,8BAK3B,YAAAW,CAAaC,GACnB,OAAOA,EAAMG,KAAKC,IACT,CACLE,KAAMF,EAAKE,KACXC,YAAaH,EAAKG,YAClB8F,aAAcjG,EAAKK,gBAKjB,6BAAM6F,CAAwBC,GAIpC,IACE,MAAMpD,QAAiBqD,MAAMD,GACvBpB,QAAoBhC,EAASgC,cAC7BsB,EAASrB,OAAOC,KAAKF,GAErBuB,EAAWvD,EAAS8B,QAAQC,IAAI,iBAAmB,aAEzD,MAAO,CAAEwB,WAAUC,cADGF,EAAOG,SAAS,WAEtC,MAAOzC,GACP,MAAM,IAAI5E,MAAM,qCAAqC4E,MAIjD,yBAAA0C,CAA0BpF,GAChC,OAAOA,EAAStB,KAAK2D,IAAa,CAChCvC,KAAMuC,EAAQvC,KACdC,QAASsF,MAAMC,QAAQjD,EAAQtC,SAC3BsC,EAAQtC,QAAQrB,KAAK6G,GACL,UAAdA,EAAKrH,KAAoB,IAAKqH,EAAMC,OAAQ,IAAKD,EAAKC,OAAQ7E,KAAM,aAA+C4E,IAErHlD,EAAQtC,YAIhB,qBAAMZ,CACJC,EACAC,EACAC,EACAC,GAQA,MAAMkG,EAAmD,GACzDrG,EAAac,SAASC,IACpBsF,EAAqBrF,KAAK,CACxBlC,KAAM,OACN2C,KAAMV,GACN,IAEJ,IAAIX,EAA4C,GAChD,GAAID,EAAY,CACd,MAAME,EACJF,EAAWG,aAAahB,KAAKiB,IACpB,CACL+F,YAAa/F,EAAWE,GACxB3B,KAAM,cACN6B,QAASJ,EAAWI,aAElB,GACRP,EAAkBD,EAAWS,SAASC,OAAO,CAAEH,KAAM,OAAQC,QAASN,QACjE,CACL,MAAMkG,QAAaC,QAAQC,IACzBxG,EAAqBX,KAAIoH,MAAO/F,IAC9B,GAAIA,EAAQM,MAAO,CACjB,MAAM4E,SAAEA,EAAQC,cAAEA,SAAwB3H,KAAKsH,wBAAwB9E,EAAQM,MAAME,KACrF,MAAO,CACLrC,KAAM,QACNsH,OAAQ,CACNtH,KAAM,SACN6H,WAAYd,EACZtE,KAAMuE,IAIV,MAAO,CACLhH,KAAM,OACN2C,KAAMd,EAAQc,MAAQ,QAK9BrB,EAAgBY,KAAK,CACnBN,KAAM,OACNC,QAAS4F,IAIb,MAAM7E,EACJxB,EAAQf,OAASe,EAAQf,MAAMyC,OAAS,EACpC,CACEzC,MAAOhB,KAAKe,aAAagB,EAAQf,OACjC2C,YAAa,CAAEhD,KAAMoB,EAAQ6B,YAAc,SAE7C,CAAE,EAEFE,EAA4C,CAChDC,MAAO/D,KAAKf,UAAUQ,aACtBgD,SAAUR,EACVwG,OAAQP,EACRlE,WAAajC,EAAQkC,WAAwB,KAC7CC,YAAcnC,EAAQmC,aAA0B,MAC7CX,GAEL,IAAIY,EAAuC,CACzCb,KAAM,GACNtC,MAAO,GACPyB,SAAU,IAEZ,IAEE,MAAMiG,EAAkB1I,KAAK6H,0BAA0B5F,GAGvDmC,QAAQC,IACN,oDACAlF,KAAKmF,UAAU4D,GACf,wBACA/I,KAAKmF,UAAUoE,IAEjB,MAAMC,QAAqB3I,KAAKoH,gBAAgB3E,SAASiC,OAAOZ,GAC1D8E,EAAWD,EAAanG,QACxBqG,EAAaF,EAAaG,YAEhC1E,QAAQC,IAAI,sCAAsClF,KAAKmF,UAAUsE,kBAAyBC,KAE1F,IAAI9D,EAA2E,GAC3E4D,IACFD,EAAgB7F,KAAK,CACnBN,KAAMoG,EAAapG,KACnBC,QAASoG,IAEX7D,EACiB,aAAf8D,GACID,GACIG,QAAQC,GAAuC,aAAtBA,EAAarI,OACvCQ,KAAK6H,IACG,CACL1G,GAAI0G,EAAa1G,GACjBhB,KAAM0H,EAAa1H,KACnB4D,UAAW/F,KAAKC,MAAMD,KAAKmF,UAAU0E,EAAapD,aAGxD,IAGRzB,EAAW,CACTb,KACEyB,EAAStB,OAAS,GAAgC,oBAA3B1B,EAAQ2B,eAC3BvE,KAAKmF,UAAUS,EAAS,GAAGG,WAC1B0D,EAAS,GAA2BtF,MAAQ,KACnDtC,MAAO+D,EACPtC,SAAUiG,GAEZ,MAAOvD,GAGP,MADAf,QAAQC,IAAI,4BAA6Bc,GACnCA,EAKR,OADAf,QAAQC,IAAI,+BAAgCF,GACrCA,EAGT,kBAAMiB,CAAa6D,EAAYC,GAE7B,IACE,MAAO,cACP,MAAO/D,GAGP,MADAf,QAAQC,IAAI,yBAA0Bc,GAChCA,GAIV,kBAAMQ,CAAawD,EAAWpH,GAE5B,IACE,MAAMqH,EAA0C,QAA5BrH,GAAS+D,gBAAwD,QAA5B/D,GAAS+D,eAA2B/D,EAAQ+D,eAAiB,MAChHuD,QAAcC,WAAGC,SAAS,kBAAkBH,KAElD,MAAO,CACLpD,YAFkC,QAAhBoD,EAAwB,aAAe,SAASA,IAGlE5G,QAAS6G,GAEX,MAAOlE,GAGP,MADAf,QAAQC,IAAI,yBAA0Bc,GAChCA,KFlNVqE,aGSA,WAAAxK,CACYC,EAAY,CACpBC,OAAQC,KAAKC,MAAMC,QAAQC,IAAIC,aAAe,MAAMkK,gBAAkBpK,QAAQC,IAAImK,gBAAkB,GACpGhK,aAAcJ,QAAQC,IAAIoK,wBAFlB1J,KAASf,UAATA,EAKVe,KAAKC,UAAUhB,GACfe,KAAK2J,aAAe,IAAIC,qBAAmB3K,EAAUC,QAG/C,SAAAe,CAAUhB,GAChB,IAAK,MAAMmB,KAAOC,OAAOC,KAAKN,KAAKf,WACjC,IAAKA,EAAUmB,GACb,MAAM,IAAIG,MAAM,aAAaH,8BAM3B,eAAAyJ,CAAgBpJ,GACtB,GAAsB,iBAAXA,GAAkC,OAAXA,EAChC,OAAOA,EAET,GAAoB,WAAhBA,EAAOE,KAAmB,CAC5B,MAAMmJ,EAAqC,CAAE,EAgB7C,OAfAzJ,OAAOC,KAAKG,GAAQkC,SAASvC,IACf,yBAARA,GAA0C,YAARA,IACxB,eAARA,EACF0J,EAAcjJ,WAAaR,OAAOC,KAAKG,EAAOI,YAAYkJ,QACxD,CAACC,EAAKC,KAAa,IACdD,EACHC,CAACA,GAAUjK,KAAK6J,gBAAgBpJ,EAAOI,WAAWoJ,OAEpD,CAAA,GAGFH,EAAc1J,GAAOK,EAAOL,OAI3B0J,EAET,GAAoB,UAAhBrJ,EAAOE,MAAoBF,EAAOK,MAAO,CAC3C,MAAMA,MAAEA,KAAUoJ,GAASzJ,EAC3B,MAAO,IACFyJ,EACHpJ,MAAOd,KAAK6J,gBAAgB/I,IAGhC,OAAOL,EAGD,YAAAM,CAAaC,GACnB,MAAMmJ,EAAYnJ,EAAMG,KAAKC,IACpB,CACLE,KAAMF,EAAKE,KACXC,YAAaH,EAAKG,YAClBC,WAAYxB,KAAK6J,gBAAgBzI,EAAKK,iBAK1C,OADA2C,QAAQC,IAAI,6BAA8BlF,KAAKmF,UAAU6F,EAAW,KAAM,IACnE,CAAC,CAAEC,qBAAsBD,IAG1B,+BAAAzI,CAAgCN,GACtC,MAAO,CACLiJ,iBAAkB,mBAClBC,eAAgBtK,KAAK6J,gBAAgBzI,EAAKK,cAItC,6BAAM6F,CAAwBC,GAIpC,IACE,MAAMpD,QAAiBqD,MAAMD,GACvBpB,QAAoBhC,EAASgC,cAC7BsB,EAASrB,OAAOC,KAAKF,GAErBuB,EAAWvD,EAAS8B,QAAQC,IAAI,iBAAmB,aAEzD,MAAO,CAAEwB,WAAUC,cADGF,EAAOG,SAAS,WAEtC,MAAOzC,GACP,MAAM,IAAI5E,MAAM,qCAAqC4E,MAIjD,yBAAA0C,CAA0BpF,GAChC,OAAOA,EAAStB,KAAK2D,IAAa,CAChCvC,KAAMuC,EAAQvC,KACdgI,MAAOzF,EAAQyF,MAAMpJ,KAAKqJ,GAAUA,EAAKC,YAAYrH,KAAQ,IAAKoH,EAAMC,WAAY,IAAKD,EAAKC,WAAYrH,KAAM,aAA0BoH,QAI9I,qBAAM5I,CACJC,EACAC,EACAC,EACAC,GAQA,MAAMkG,EAAgC,CACpC3F,KAAM,QACNgI,MAAO,IAET1I,EAAac,SAASC,IACpBsF,EAAqBqC,MAAM1H,KAAK,CAC9BS,KAAMV,GACN,IAEJ,IAAIX,EAA6B,GACjC,GAAID,EAAY,CACd,MAAM0I,EACJ1I,EAAWG,aAAahB,KAAKiB,IACpB,CAAEkB,KAAMlB,EAAWI,aACtB,GACRP,EAAkBD,EAAWS,SAASC,OAAO,CAAEH,KAAM,OAAQgI,MAAOG,QAC/D,CACL,MAAMA,QAAiBrC,QAAQC,IAC7BxG,EAAqBX,KAAIoH,MAAO/F,IAC9B,GAAIA,EAAQM,MAAO,CACjB,MAAM4E,SAAEA,EAAQC,cAAEA,SAAwB3H,KAAKsH,wBAAwB9E,EAAQM,MAAME,KACrF,MAAO,CACLyH,WAAY,CACV/C,SAAUA,EACVtE,KAAMuE,IAIV,MAAO,CAAErE,KAAMd,EAAQc,MAAQ,QAIrCrB,EAAgBY,KAAK,CAAEN,KAAM,OAAQgI,MAAOG,IAG9C,IAAInH,EAAc,CAAE,EAChBC,EAAkB,CAAE,EACpBzB,EAAQf,OAASe,EAAQf,MAAMyC,OAAS,IAC1CF,EAC6B,aAA3BxB,EAAQ2B,eACJ,CACE1C,MAAOhB,KAAKe,aAAagB,EAAQf,OACjC2J,WAAY,CACVC,sBAAuB,CACrBC,KAAOC,OAAO/I,EAAQ6B,YAAYmH,eAAyCC,EAAAA,oBAAoBC,QAIrG,CAAE,EACRzH,EAA6C,oBAA3BzB,EAAQ2B,eAAuC1D,KAAK0B,gCAAgCK,EAAQf,MAAM,IAAM,CAAE,GAG9H,MAAMkK,EAA2B,CAC/BC,eAAgB,CACd,CACEC,SAAUC,EAAYA,aAACC,gCACvBC,UAAWC,EAAkBA,mBAACC,kBAGlCC,iBAAkB,CAChBC,gBAAkB5J,EAAQkC,WAAwB,KAClDC,YAAcnC,EAAQmC,aAA0B,MAC7CV,GAELO,MAAO/D,KAAKf,UAAUQ,aACtBmM,kBAAmB1D,KAChB3E,GAEL,IAAIY,EAAuC,CACzCb,KAAM,GACNtC,MAAO,GACPyB,SAAU,IAEZ,IAEE,MAAMiG,EAAkB1I,KAAK6H,0BAA0B5F,GAGvDmC,QAAQC,IAAI,+CAAgDlF,KAAKmF,UAAUoE,IAE3E,MAGMC,SAHmB3I,KAAK2J,aAAakC,mBAAmBX,GAAaY,gBAAgB,CACzFlD,SAAU3G,KAEoBkC,SAC1Bb,EAAOqF,EAAarF,OACpByI,EAAYpD,EAAaqD,gBACzBpH,EAAe+D,EAAasD,YAActD,EAAasD,WAAW,GAAGrH,aAE3ER,QAAQC,IAAI,2CAA2Cf,6BAAgCnE,KAAKmF,UAAUyH,oBAA4BnH,KAElI,IAAIG,EAA2E,GAC/E,GAAI4D,EAAc,CAChB,MAAM4B,EAA4B,GAClCxF,EAAWgH,GACPA,GAAW5K,KAAK+K,IACd3B,EAAM1H,KAAK,CAAEsJ,aAAcD,IACpB,CACL5J,GAAI,GACJhB,KAAM4K,EAAS5K,KACf4D,UAAW/F,KAAKC,MAAMD,KAAKmF,UAAU4H,EAASE,YAGlD,GACJ1D,EAAgB7F,KAAK,CAAEN,KAAM,QAASgI,MAAOA,IAG/CpG,EAAW,CACTb,KAAMA,EACNtC,MAAO+D,EACPtC,SAAUiG,GAEZ,MAAOvD,GAGP,MADAf,QAAQC,IAAI,4BAA6Bc,GACnCA,EAKR,OADAf,QAAQC,IAAI,+BAAgCF,GACrCA,EAGT,kBAAMiB,CAAa6D,EAAYC,GAE7B,IACE,MAAO,cACP,MAAO/D,GAGP,MADAf,QAAQC,IAAI,yBAA0Bc,GAChCA,GAIV,kBAAMQ,CAAawD,EAAWpH,GAE5B,IACE,MAAMqH,EAA0C,QAA5BrH,GAAS+D,gBAAwD,QAA5B/D,GAAS+D,eAA2B/D,EAAQ+D,eAAiB,MAChHuD,QAAcC,WAAGC,SAAS,kBAAkBH,KAElD,MAAO,CACLpD,YAFkC,QAAhBoD,EAAwB,aAAe,SAASA,IAGlE5G,QAAS6G,GAEX,MAAOlE,GAGP,MADAf,QAAQC,IAAI,yBAA0Bc,GAChCA,KHtQVkH,WILA,WAAArN,CACYC,EAAY,CACpBC,OAAQC,KAAKC,MAAMC,QAAQC,IAAIC,aAAe,MAAM+M,cAAgBjN,QAAQC,IAAIgN,cAAgB,GAChG7M,aAAcJ,QAAQC,IAAIiN,sBAFlBvM,KAASf,UAATA,EAKVe,KAAKC,UAAUhB,GACfe,KAAKwM,WAAa,IAAIH,EAAIA,KAAC,CAAEnN,OAAQD,EAAUC,SAGzC,SAAAe,CAAUhB,GAChB,IAAK,MAAMmB,KAAOC,OAAOC,KAAKN,KAAKf,WACjC,IAAKA,EAAUmB,GACb,MAAM,IAAIG,MAAM,aAAaH,8BAK3B,YAAAW,CAAaC,GACnB,OAAOA,EAAMG,KAAKC,IACT,CACLT,KAAM,WACNU,SAAU,CACRC,KAAMF,EAAKE,KACXC,YAAaH,EAAKG,YAClBC,WAAYJ,EAAKK,iBAMzB,qBAAMG,CACJC,EACAC,EACAC,EACAC,GAQA,IAAIC,EAA0D,GAC9D,GAAID,EAAY,CACd,MAAME,EACJF,EAAWG,aAAahB,KAAKiB,IACpB,CACLC,aAAcD,EAAWE,GACzBC,KAAM,OACNC,QAASJ,EAAWI,aAElB,GACRP,EAAkBD,EAAWS,SAASC,OAAOR,OACxC,CAGYJ,EAAqB2K,MAAMjK,GAAYA,EAAQM,QAE9Db,EAAgBY,KAAK,CACnBN,KAAM,OACNC,QAASX,EAAaV,KAAKyB,IAClB,CACLjC,KAAM,OACN2C,KAAMV,QAKZf,EAAac,SAASC,IACpBX,EAAgBY,KAAK,CACnBN,KAAM,SACNC,QAASI,GACT,IAINX,EAAgBY,KAAK,CACnBN,KAAM,OACNC,QAASV,EAAqBX,KAAKqB,GAC1BA,EAAQM,MACX,CACEnC,KAAM,YACNoC,UAAW,CACTC,IAAKR,EAAQM,MAAME,IACnBC,OAAQT,EAAQM,MAAMG,QAAU,SAGpC,CACEtC,KAAM,OACN2C,KAAMd,EAAQc,MAAQ,QAMlC,IAAIC,EAAc,CAAE,EAChBC,EAAkB,CAAE,EACpBzB,EAAQf,OAASe,EAAQf,MAAMyC,OAAS,IAC1CF,EAC6B,aAA3BxB,EAAQ2B,eACJ,CACE1C,MAAOhB,KAAKe,aAAagB,EAAQf,OACjC2C,YAAa5B,EAAQ6B,YAAe,QAEtC,CAAE,EACRJ,EAC6B,oBAA3BzB,EAAQ2B,eACJ,CACEG,gBAAiB,CACflD,KAAM,gBAGV,CAAE,GAGV,MAAMmD,EAAa,CACjBC,MAAO/D,KAAKf,UAAUQ,aACtBgD,SAAUR,EACV+B,WAAajC,EAAQkC,WAAwB,KAC7CC,YAAcnC,EAAQmC,aAA0B,MAC7CX,KACAC,GAEL,IAAIW,EAAuC,CACzCb,KAAM,GACNtC,MAAO,GACPyB,SAAU,IAEZ,IAEE2B,QAAQC,IAAI,+CAAgDlF,KAAKmF,UAAUrC,IAC3E,MACMsC,SADqBvE,KAAKwM,WAAWhI,KAAKC,YAAYC,OAAOZ,IACvCa,QAAQ,GAC9BC,EAAeL,EAAOM,cAE5BT,QAAQC,IAAI,gDAAgDlF,KAAKmF,UAAUC,EAAOO,0BAA0BF,KAE5G,IAAIG,EAA2E,GAC3ER,EAAOO,UACT7C,EAAgBY,KAAK0B,EAAOO,SAC5BC,EACmB,eAAjBH,GACIL,EAAOO,QAAQE,YAAY7D,KAAK8D,IACvB,CACL3C,GAAI2C,EAAU3C,GACdhB,KAAM2D,EAAU5D,SAASC,KACzB4D,UAAW/F,KAAKC,MAAM6F,EAAU5D,SAAS6D,gBAG7C,IAGRf,EAAW,CACTb,KAAMiB,EAAOO,SAAStC,QACtBxB,MAAO+D,EACPtC,SAAUR,GAEZ,MAAOkD,GAGP,MADAf,QAAQC,IAAI,4BAA6Bc,GACnCA,EAKR,OADAf,QAAQC,IAAI,+BAAgCF,GACrCA,EAGT,kBAAMiB,CAAa6D,EAAYC,GAE7B,IACE,MAAO,cACP,MAAO/D,GAGP,MADAf,QAAQC,IAAI,yBAA0Bc,GAChCA,GAIV,kBAAMQ,CAAawD,EAAWpH,GAE5B,IACE,MAAMqH,EAA0C,QAA5BrH,GAAS+D,gBAAwD,QAA5B/D,GAAS+D,eAA2B/D,EAAQ+D,eAAiB,MAChHuD,QAAcC,WAAGC,SAAS,kBAAkBH,KAElD,MAAO,CACLpD,YAFkC,QAAhBoD,EAAwB,aAAe,SAASA,IAGlE5G,QAAS6G,GAEX,MAAOlE,GAGP,MADAf,QAAQC,IAAI,yBAA0Bc,GAChCA,MCvMCuH,EAAmCC,EAACA,EAACC,OAAO,CACvDtJ,KAAMqJ,EAACA,EAACE,SAASC,WACjB9L,MAAO2L,EAACA,EAACI,MACPJ,EAAAA,EAAEC,OAAO,CACPtK,GAAIqK,EAACA,EAACE,SACNvL,KAAMqL,EAACA,EAACE,SACR3H,UAAWyH,EAAAA,EAAEK,OAAOL,EAACA,EAACM,UAG1BxK,SAAUkK,EAAAA,EAAEI,MAAMJ,EAACA,EAACM,SAGTC,EAAkCP,EAACA,EAACC,OAAO,CACtDtJ,KAAMqJ,EAACA,EAACE,SAASM,WACjBrK,MAAO6J,EAAAA,EACJC,OAAO,CACN5J,IAAK2J,EAACA,EAACE,SACP5J,OAAQ0J,EAACA,EAACM,MAAME,aAEjBA,WACHjK,MAAOyJ,EAAAA,EACJC,OAAO,CACNxJ,KAAMuJ,EAACA,EAACE,SACRxJ,OAAQsJ,EAACA,EAACM,MAAME,aAEjBA,aAGQC,EAAkCT,EAAAA,EAC5CC,OAAO,CACN5L,MAAO2L,EAACA,EAACI,MAAMJ,EAACA,EAACM,OAAOE,WACxBvJ,WAAY+I,EAACA,EAACM,MAAME,WACpBzJ,eAAgBiJ,EAACA,EAACU,KAAK,CAAC,WAAY,oBAAoBF,aAEzDG,SAASX,EAAAA,EAAEM,OAEDM,EAAgCZ,EAACA,EAACC,OAAO,CACpD5G,YAAa2G,EAACA,EAACE,SACfrK,QAASmK,EAAAA,EAAEa,WAAWpH,UAGXqH,EAAgBd,EAACA,EAACC,OAAO,CACpCtL,KAAMqL,EAACA,EAACE,SACRtL,YAAaoL,EAACA,EAACE,SACfpL,YAAakL,EAACA,EAACC,OAAO,CACpBjM,KAAMgM,EAACA,EAACE,SACRhM,WAAY8L,EAAAA,EAAEK,OAAOL,EAACA,EAACM,OACvBS,SAAUf,EAAAA,EAAEI,MAAMJ,EAACA,EAACE,iQLjCGc,GAElB,IAAIC,EADatH,EAAkBqH"}